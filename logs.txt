* 
* ==> Audit <==
* |-----------|----------------------------|----------|-------|---------|---------------------|---------------------|
|  Command  |            Args            | Profile  | User  | Version |     Start Time      |      End Time       |
|-----------|----------------------------|----------|-------|---------|---------------------|---------------------|
| start     | --memory 3924              | minikube | qubit | v1.31.1 | 24 Jul 23 16:52 UTC |                     |
| stop      |                            | minikube | qubit | v1.31.1 | 24 Jul 23 16:52 UTC | 24 Jul 23 16:52 UTC |
| start     | --memory 3924              | minikube | qubit | v1.31.1 | 24 Jul 23 16:52 UTC | 24 Jul 23 16:52 UTC |
| addons    | list                       | minikube | qubit | v1.31.1 | 24 Jul 23 16:58 UTC | 24 Jul 23 16:58 UTC |
| addons    | enable dashboard           | minikube | qubit | v1.31.1 | 24 Jul 23 16:58 UTC | 24 Jul 23 16:58 UTC |
| addons    | enable metrics-server      | minikube | qubit | v1.31.1 | 24 Jul 23 16:58 UTC | 24 Jul 23 16:58 UTC |
| dashboard |                            | minikube | qubit | v1.31.1 | 24 Jul 23 16:58 UTC |                     |
| start     | --memory 3920              | minikube | qubit | v1.31.1 | 24 Jul 23 17:11 UTC | 24 Jul 23 17:11 UTC |
| stop      |                            | minikube | qubit | v1.31.1 | 24 Jul 23 17:19 UTC | 24 Jul 23 17:19 UTC |
| start     | --memory 3920              | minikube | qubit | v1.31.1 | 24 Jul 23 17:19 UTC | 24 Jul 23 17:19 UTC |
| delete    |                            | minikube | qubit | v1.31.1 | 24 Jul 23 17:21 UTC | 24 Jul 23 17:21 UTC |
| start     | --memory 3920              | minikube | qubit | v1.31.1 | 24 Jul 23 17:21 UTC |                     |
| start     | --memory 3200              | minikube | qubit | v1.31.1 | 24 Jul 23 17:22 UTC | 24 Jul 23 17:24 UTC |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 24 Jul 23 17:28 UTC | 24 Jul 23 17:28 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 09:39 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 09:45 UTC |                     |
| start     | --memory=3200mb            | minikube | qubit | v1.31.1 | 25 Jul 23 09:45 UTC |                     |
| start     | --memory=3200mb            | minikube | qubit | v1.31.1 | 25 Jul 23 09:46 UTC | 25 Jul 23 09:46 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 09:59 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 10:01 UTC | 25 Jul 23 10:02 UTC |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 10:44 UTC |                     |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 10:44 UTC |                     |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 10:48 UTC | 25 Jul 23 10:49 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 10:57 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 10:58 UTC | 25 Jul 23 11:01 UTC |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 11:04 UTC |                     |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 11:07 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 11:08 UTC | 25 Jul 23 11:09 UTC |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 11:10 UTC | 25 Jul 23 11:11 UTC |
| service   | wordpress --url            | minikube | qubit | v1.31.1 | 25 Jul 23 11:13 UTC | 25 Jul 23 11:13 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 13:52 UTC |                     |
| start     | --memory=3936              | minikube | qubit | v1.31.1 | 25 Jul 23 13:53 UTC | 25 Jul 23 13:54 UTC |
| service   | kibana-external -n logging | minikube | qubit | v1.31.1 | 25 Jul 23 14:01 UTC |                     |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 14:01 UTC | 25 Jul 23 14:01 UTC |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 14:02 UTC | 25 Jul 23 14:02 UTC |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 14:26 UTC | 25 Jul 23 14:26 UTC |
| service   | elasticsearch -n logging   | minikube | qubit | v1.31.1 | 25 Jul 23 14:31 UTC | 25 Jul 23 14:31 UTC |
| service   | fluentd -n logging         | minikube | qubit | v1.31.1 | 25 Jul 23 14:31 UTC |                     |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 14:33 UTC | 25 Jul 23 14:33 UTC |
| service   | wordpress -n default       | minikube | qubit | v1.31.1 | 25 Jul 23 14:35 UTC | 25 Jul 23 14:35 UTC |
| service   | wordpress -n default       | minikube | qubit | v1.31.1 | 25 Jul 23 14:38 UTC | 25 Jul 23 14:39 UTC |
| service   | fluentd                    | minikube | qubit | v1.31.1 | 25 Jul 23 15:34 UTC |                     |
| service   | fluentd -n logging         | minikube | qubit | v1.31.1 | 25 Jul 23 15:34 UTC |                     |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 16:30 UTC | 25 Jul 23 16:30 UTC |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 16:53 UTC | 25 Jul 23 16:54 UTC |
| stop      |                            | minikube | qubit | v1.31.1 | 25 Jul 23 17:12 UTC | 25 Jul 23 17:16 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 17:16 UTC | 25 Jul 23 17:18 UTC |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 17:23 UTC |                     |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 17:24 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 17:25 UTC | 25 Jul 23 17:26 UTC |
| service   | wordpress                  | minikube | qubit | v1.31.1 | 25 Jul 23 17:27 UTC | 25 Jul 23 17:27 UTC |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 17:27 UTC | 25 Jul 23 17:28 UTC |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 17:30 UTC | 25 Jul 23 17:30 UTC |
| service   | kibana -n logging          | minikube | qubit | v1.31.1 | 25 Jul 23 17:34 UTC | 25 Jul 23 17:35 UTC |
| kubectl   | get pod                    | minikube | qubit | v1.31.1 | 25 Jul 23 17:45 UTC | 25 Jul 23 17:45 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 17:53 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 18:04 UTC |                     |
| service   | kibana                     | minikube | qubit | v1.31.1 | 25 Jul 23 18:04 UTC |                     |
| start     |                            | minikube | qubit | v1.31.1 | 25 Jul 23 18:27 UTC | 25 Jul 23 18:30 UTC |
| start     |                            | minikube | qubit | v1.31.1 | 26 Jul 23 09:56 UTC |                     |
|-----------|----------------------------|----------|-------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/07/26 09:56:36
Running on machine: qubit
Binary: Built with gc go1.20.6 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0726 09:56:36.393119 3032343 out.go:296] Setting OutFile to fd 1 ...
I0726 09:56:36.393339 3032343 out.go:348] isatty.IsTerminal(1) = true
I0726 09:56:36.393344 3032343 out.go:309] Setting ErrFile to fd 2...
I0726 09:56:36.393347 3032343 out.go:348] isatty.IsTerminal(2) = true
I0726 09:56:36.393569 3032343 root.go:338] Updating PATH: /home/qubit/.minikube/bin
I0726 09:56:36.599083 3032343 out.go:303] Setting JSON to false
I0726 09:56:36.727197 3032343 start.go:128] hostinfo: {"hostname":"qubit","uptime":497730,"bootTime":1689867666,"procs":305,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"20.04","kernelVersion":"5.4.0-81-generic","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"6962f986-a07a-4b68-8c02-6d79043443ce"}
I0726 09:56:36.727272 3032343 start.go:138] virtualization:  
I0726 09:56:36.866668 3032343 out.go:177] 😄  minikube v1.31.1 on Ubuntu 20.04
I0726 09:56:36.867993 3032343 notify.go:220] Checking for updates...
I0726 09:56:36.931642 3032343 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.3
I0726 09:56:36.933307 3032343 driver.go:373] Setting default libvirt URI to qemu:///system
I0726 09:56:40.197170 3032343 docker.go:121] docker version: linux-20.10.21:
I0726 09:56:40.197408 3032343 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0726 09:56:40.874545 3032343 info.go:266] docker info: {ID:BPN2:PIRA:2ED6:TNNV:SXQV:MLHR:7CL4:535E:PGVW:IQC7:4SDA:4DJP Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:32 OomKillDisable:true NGoroutines:39 SystemTime:2023-07-26 09:56:40.312110218 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.4.0-81-generic OperatingSystem:Ubuntu 20.04.3 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:4127289344 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http://172.16.10.20:3128/ HTTPSProxy:http://172.16.10.20:3128/ NoProxy:localhost,127.0.0.1,192.168.58.2,docker-registry.example.com,.corp Name:qubit Labels:[] ExperimentalBuild:false ServerVersion:20.10.21 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID: Expected:} RuncCommit:{ID: Expected:} InitCommit:{ID: Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No swap limit support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[] Warnings:<nil>}}
I0726 09:56:40.874610 3032343 docker.go:294] overlay module found
I0726 09:56:40.915513 3032343 out.go:177] ✨  Using the docker driver based on existing profile
I0726 09:56:40.972014 3032343 start.go:298] selected driver: docker
I0726 09:56:40.972023 3032343 start.go:898] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40 Memory:3200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/qubit:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0726 09:56:40.972098 3032343 start.go:909] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0726 09:56:40.972213 3032343 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0726 09:56:41.082746 3032343 info.go:266] docker info: {ID:BPN2:PIRA:2ED6:TNNV:SXQV:MLHR:7CL4:535E:PGVW:IQC7:4SDA:4DJP Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:32 OomKillDisable:true NGoroutines:39 SystemTime:2023-07-26 09:56:41.025086926 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:5.4.0-81-generic OperatingSystem:Ubuntu 20.04.3 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:4127289344 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http://172.16.10.20:3128/ HTTPSProxy:http://172.16.10.20:3128/ NoProxy:localhost,127.0.0.1,192.168.58.2,docker-registry.example.com,.corp Name:qubit Labels:[] ExperimentalBuild:false ServerVersion:20.10.21 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID: Expected:} RuncCommit:{ID: Expected:} InitCommit:{ID: Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No swap limit support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[] Warnings:<nil>}}
I0726 09:56:41.101488 3032343 out.go:177] 
W0726 09:56:41.151128 3032343 out.go:239] 🧯  The requested memory allocation of 3200MiB does not leave room for system overhead (total system memory: 3936MiB). You may face stability issues.
W0726 09:56:41.151609 3032343 out.go:239] 💡  Suggestion: Start minikube with less memory allocated: 'minikube start --memory=2200mb'
I0726 09:56:41.170894 3032343 out.go:177] 
I0726 09:56:41.178858 3032343 cni.go:84] Creating CNI manager for ""
I0726 09:56:41.178876 3032343 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0726 09:56:41.178886 3032343 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40 Memory:3200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/qubit:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0726 09:56:41.180780 3032343 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I0726 09:56:41.181361 3032343 cache.go:122] Beginning downloading kic base image for docker with docker
I0726 09:56:41.181898 3032343 out.go:177] 🚜  Pulling base image ...
I0726 09:56:41.209765 3032343 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.40 in local docker daemon
I0726 09:56:41.209796 3032343 preload.go:132] Checking if preload exists for k8s version v1.27.3 and runtime docker
I0726 09:56:41.209828 3032343 preload.go:148] Found local preload: /home/qubit/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.3-docker-overlay2-amd64.tar.lz4
I0726 09:56:41.209837 3032343 cache.go:57] Caching tarball of preloaded images
I0726 09:56:41.209898 3032343 preload.go:174] Found /home/qubit/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0726 09:56:41.209901 3032343 cache.go:60] Finished verifying existence of preloaded tar for  v1.27.3 on docker
I0726 09:56:41.209989 3032343 profile.go:148] Saving config to /home/qubit/.minikube/profiles/minikube/config.json ...
I0726 09:56:41.468699 3032343 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.40 in local docker daemon, skipping pull
I0726 09:56:41.468712 3032343 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.40 exists in daemon, skipping load
I0726 09:56:41.468725 3032343 cache.go:195] Successfully downloaded all kic artifacts
I0726 09:56:41.479053 3032343 start.go:365] acquiring machines lock for minikube: {Name:mk9992101986d61a08e2e4a6cfafe1686e470c31 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0726 09:56:41.479124 3032343 start.go:369] acquired machines lock for "minikube" in 40.746µs
I0726 09:56:41.479137 3032343 start.go:96] Skipping create...Using existing machine configuration
I0726 09:56:41.479141 3032343 fix.go:54] fixHost starting: 
I0726 09:56:41.479330 3032343 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0726 09:56:41.649788 3032343 fix.go:102] recreateIfNeeded on minikube: state=Running err=<nil>
W0726 09:56:41.649811 3032343 fix.go:128] unexpected machine state, will restart: <nil>
I0726 09:56:41.712504 3032343 out.go:177] 🏃  Updating the running docker "minikube" container ...
I0726 09:56:41.712992 3032343 machine.go:88] provisioning docker machine ...
I0726 09:56:41.713012 3032343 ubuntu.go:169] provisioning hostname "minikube"
I0726 09:56:41.713064 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:41.846509 3032343 main.go:141] libmachine: Using SSH client type: native
I0726 09:56:41.873683 3032343 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x80eb00] 0x811ba0 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0726 09:56:41.873694 3032343 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0726 09:56:44.555992 3032343 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0726 09:56:44.556050 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:44.610258 3032343 main.go:141] libmachine: Using SSH client type: native
I0726 09:56:44.610578 3032343 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x80eb00] 0x811ba0 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0726 09:56:44.610587 3032343 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0726 09:56:44.783427 3032343 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0726 09:56:44.783441 3032343 ubuntu.go:175] set auth options {CertDir:/home/qubit/.minikube CaCertPath:/home/qubit/.minikube/certs/ca.pem CaPrivateKeyPath:/home/qubit/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/qubit/.minikube/machines/server.pem ServerKeyPath:/home/qubit/.minikube/machines/server-key.pem ClientKeyPath:/home/qubit/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/qubit/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/qubit/.minikube}
I0726 09:56:44.783458 3032343 ubuntu.go:177] setting up certificates
I0726 09:56:44.783472 3032343 provision.go:83] configureAuth start
I0726 09:56:44.783520 3032343 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0726 09:56:44.845881 3032343 provision.go:138] copyHostCerts
I0726 09:56:44.845922 3032343 exec_runner.go:144] found /home/qubit/.minikube/ca.pem, removing ...
I0726 09:56:44.845927 3032343 exec_runner.go:203] rm: /home/qubit/.minikube/ca.pem
I0726 09:56:44.994592 3032343 exec_runner.go:151] cp: /home/qubit/.minikube/certs/ca.pem --> /home/qubit/.minikube/ca.pem (1074 bytes)
I0726 09:56:45.025461 3032343 exec_runner.go:144] found /home/qubit/.minikube/cert.pem, removing ...
I0726 09:56:45.025471 3032343 exec_runner.go:203] rm: /home/qubit/.minikube/cert.pem
I0726 09:56:45.025512 3032343 exec_runner.go:151] cp: /home/qubit/.minikube/certs/cert.pem --> /home/qubit/.minikube/cert.pem (1119 bytes)
I0726 09:56:45.025756 3032343 exec_runner.go:144] found /home/qubit/.minikube/key.pem, removing ...
I0726 09:56:45.025761 3032343 exec_runner.go:203] rm: /home/qubit/.minikube/key.pem
I0726 09:56:45.025779 3032343 exec_runner.go:151] cp: /home/qubit/.minikube/certs/key.pem --> /home/qubit/.minikube/key.pem (1675 bytes)
I0726 09:56:45.025961 3032343 provision.go:112] generating server cert: /home/qubit/.minikube/machines/server.pem ca-key=/home/qubit/.minikube/certs/ca.pem private-key=/home/qubit/.minikube/certs/ca-key.pem org=qubit.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0726 09:56:45.211811 3032343 provision.go:172] copyRemoteCerts
I0726 09:56:45.211900 3032343 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0726 09:56:45.211937 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:45.231293 3032343 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/qubit/.minikube/machines/minikube/id_rsa Username:docker}
I0726 09:56:45.359017 3032343 ssh_runner.go:362] scp /home/qubit/.minikube/machines/server.pem --> /etc/docker/server.pem (1200 bytes)
I0726 09:56:45.459252 3032343 ssh_runner.go:362] scp /home/qubit/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0726 09:56:45.482120 3032343 ssh_runner.go:362] scp /home/qubit/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0726 09:56:45.500666 3032343 provision.go:86] duration metric: configureAuth took 717.184774ms
I0726 09:56:45.500683 3032343 ubuntu.go:193] setting minikube options for container-runtime
I0726 09:56:45.500816 3032343 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.3
I0726 09:56:45.500857 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:45.521845 3032343 main.go:141] libmachine: Using SSH client type: native
I0726 09:56:45.522179 3032343 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x80eb00] 0x811ba0 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0726 09:56:45.522186 3032343 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0726 09:56:45.692286 3032343 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0726 09:56:45.692301 3032343 ubuntu.go:71] root file system type: overlay
I0726 09:56:45.692389 3032343 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0726 09:56:45.692439 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:45.711967 3032343 main.go:141] libmachine: Using SSH client type: native
I0726 09:56:45.712336 3032343 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x80eb00] 0x811ba0 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0726 09:56:45.712384 3032343 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment="HTTP_PROXY=http://172.16.10.20:3128"
Environment="HTTPS_PROXY=http://172.16.10.20:3128"
Environment="NO_PROXY=127.0.0.1"


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0726 09:56:45.844017 3032343 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment=HTTP_PROXY=http://172.16.10.20:3128
Environment=HTTPS_PROXY=http://172.16.10.20:3128
Environment=NO_PROXY=127.0.0.1


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0726 09:56:45.844076 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:45.901198 3032343 main.go:141] libmachine: Using SSH client type: native
I0726 09:56:45.901547 3032343 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x80eb00] 0x811ba0 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0726 09:56:45.901557 3032343 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0726 09:56:46.116569 3032343 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0726 09:56:46.116587 3032343 machine.go:91] provisioned docker machine in 4.403583198s
I0726 09:56:46.116596 3032343 start.go:300] post-start starting for "minikube" (driver="docker")
I0726 09:56:46.116603 3032343 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0726 09:56:46.116659 3032343 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0726 09:56:46.116692 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:46.136045 3032343 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/qubit/.minikube/machines/minikube/id_rsa Username:docker}
I0726 09:56:46.397661 3032343 ssh_runner.go:195] Run: cat /etc/os-release
I0726 09:56:46.426031 3032343 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0726 09:56:46.426053 3032343 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0726 09:56:46.426059 3032343 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0726 09:56:46.426063 3032343 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I0726 09:56:46.426071 3032343 filesync.go:126] Scanning /home/qubit/.minikube/addons for local assets ...
I0726 09:56:46.426107 3032343 filesync.go:126] Scanning /home/qubit/.minikube/files for local assets ...
I0726 09:56:46.426119 3032343 start.go:303] post-start completed in 309.519392ms
I0726 09:56:46.426185 3032343 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0726 09:56:46.426221 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:46.478771 3032343 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/qubit/.minikube/machines/minikube/id_rsa Username:docker}
I0726 09:56:46.702803 3032343 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0726 09:56:46.707664 3032343 out.go:177] 
W0726 09:56:46.708214 3032343 out.go:239] 🧯  Docker is nearly out of disk space, which may cause deployments to fail! (94%!o(MISSING)f capacity). You can pass '--force' to skip this check.
W0726 09:56:46.708246 3032343 out.go:239] 💡  Suggestion: 

    Try one or more of the following to free up space on the device:
    
    1. Run "docker system prune" to remove unused Docker data (optionally with "-a")
    2. Increase the storage allocated to Docker for Desktop by clicking on:
    Docker icon > Preferences > Resources > Disk Image Size
    3. Run "minikube ssh -- docker system prune" if using the Docker container runtime
W0726 09:56:46.708264 3032343 out.go:239] 🍿  Related issue: https://github.com/kubernetes/minikube/issues/9024
I0726 09:56:46.709191 3032343 out.go:177] 
I0726 09:56:46.709849 3032343 fix.go:56] fixHost completed within 5.230703773s
I0726 09:56:46.709858 3032343 start.go:83] releasing machines lock for "minikube", held for 5.230728956s
I0726 09:56:46.709905 3032343 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0726 09:56:46.729923 3032343 out.go:177] 🌐  Found network options:
I0726 09:56:46.730311 3032343 out.go:177]     ▪ http_proxy=http://172.16.10.20:3128
W0726 09:56:46.769000 3032343 out.go:239] ❗  You appear to be using a proxy, but your NO_PROXY environment does not include the minikube IP (192.168.49.2).
I0726 09:56:46.769491 3032343 out.go:177] 📘  Please see https://minikube.sigs.k8s.io/docs/handbook/vpn_and_proxy/ for more details
I0726 09:56:46.770066 3032343 out.go:177]     ▪ https_proxy=http://172.16.10.20:3128
I0726 09:56:46.770619 3032343 out.go:177]     ▪ no_proxy=127.0.0.1
I0726 09:56:46.771081 3032343 ssh_runner.go:195] Run: cat /version.json
I0726 09:56:46.771118 3032343 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0726 09:56:46.790843 3032343 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/qubit/.minikube/machines/minikube/id_rsa Username:docker}
I0726 09:56:46.876193 3032343 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0726 09:56:46.961296 3032343 ssh_runner.go:195] Run: systemctl --version
I0726 09:56:49.113920 3032343 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (2.237692621s)
W0726 09:56:49.113943 3032343 start.go:815] [curl -sS -m 2 https://registry.k8s.io/] failed: curl -sS -m 2 https://registry.k8s.io/: Process exited with status 28
stdout:

stderr:
curl: (28) Failed to connect to registry.k8s.io port 443 after 1315 ms: Connection timed out
I0726 09:56:49.114002 3032343 ssh_runner.go:235] Completed: systemctl --version: (2.152696169s)
W0726 09:56:49.114010 3032343 out.go:239] ❗  This container is having trouble accessing https://registry.k8s.io
W0726 09:56:49.114031 3032343 out.go:239] 💡  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
I0726 09:56:49.114068 3032343 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0726 09:56:49.145945 3032343 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0726 09:56:49.372698 3032343 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0726 09:56:49.372769 3032343 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0726 09:56:49.379932 3032343 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0726 09:56:49.379946 3032343 start.go:466] detecting cgroup driver to use...
I0726 09:56:49.379969 3032343 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0726 09:56:49.380066 3032343 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0726 09:56:49.392307 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0726 09:56:49.504755 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0726 09:56:49.520206 3032343 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0726 09:56:49.520258 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0726 09:56:49.527324 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0726 09:56:49.534251 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0726 09:56:49.540764 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0726 09:56:49.554783 3032343 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0726 09:56:49.599801 3032343 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0726 09:56:49.607937 3032343 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0726 09:56:49.657710 3032343 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0726 09:56:49.664317 3032343 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0726 09:56:52.169979 3032343 ssh_runner.go:235] Completed: sudo systemctl daemon-reload: (2.505644433s)
I0726 09:56:52.170033 3032343 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0726 09:57:18.341109 3032343 ssh_runner.go:235] Completed: sudo systemctl restart containerd: (26.171060211s)
I0726 09:57:18.341120 3032343 start.go:466] detecting cgroup driver to use...
I0726 09:57:18.341143 3032343 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0726 09:57:18.341193 3032343 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0726 09:57:18.354956 3032343 cruntime.go:276] skipping containerd shutdown because we are bound to it
I0726 09:57:18.355002 3032343 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0726 09:57:18.424992 3032343 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0726 09:57:18.437808 3032343 ssh_runner.go:195] Run: which cri-dockerd
I0726 09:57:18.521588 3032343 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0726 09:57:18.527983 3032343 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0726 09:57:18.540926 3032343 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0726 09:57:18.893635 3032343 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0726 09:57:19.007100 3032343 docker.go:535] configuring docker to use "cgroupfs" as cgroup driver...
I0726 09:57:19.007122 3032343 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0726 09:57:19.114741 3032343 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0726 09:57:19.212708 3032343 ssh_runner.go:195] Run: sudo systemctl restart docker
I0726 09:57:38.333047 3032343 ssh_runner.go:235] Completed: sudo systemctl restart docker: (19.120311178s)
I0726 09:57:38.333106 3032343 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0726 09:57:38.423263 3032343 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0726 09:57:38.505961 3032343 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0726 09:57:38.590013 3032343 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0726 09:57:38.670172 3032343 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0726 09:57:40.314945 3032343 ssh_runner.go:235] Completed: sudo systemctl restart cri-docker.socket: (1.64475288s)
I0726 09:57:40.315004 3032343 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0726 09:57:40.406959 3032343 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0726 09:57:42.560586 3032343 ssh_runner.go:235] Completed: sudo systemctl restart cri-docker: (2.153606939s)
I0726 09:57:42.560602 3032343 start.go:513] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0726 09:57:42.560654 3032343 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0726 09:57:42.563909 3032343 start.go:534] Will wait 60s for crictl version
I0726 09:57:42.563952 3032343 ssh_runner.go:195] Run: which crictl
I0726 09:57:42.567059 3032343 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0726 09:58:47.269481 3032343 ssh_runner.go:235] Completed: sudo /usr/bin/crictl version: (1m4.702400843s)
I0726 09:58:47.417890 3032343 out.go:177] 
W0726 09:58:47.437720 3032343 out.go:239] ❌  Exiting due to RUNTIME_ENABLE: Failed to start container runtime: Temporary Error: sudo /usr/bin/crictl version: Process exited with status 1
stdout:

stderr:
time="2023-07-26T09:58:47Z" level=fatal msg="unable to determine runtime API version: rpc error: code = DeadlineExceeded desc = context deadline exceeded"

W0726 09:58:47.437748 3032343 out.go:239] 
W0726 09:58:47.438432 3032343 out.go:239] [31m╭───────────────────────────────────────────────────────────────────────────────────────────╮[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    😿  If the above advice does not help, please let us know:                             [31m│[0m
[31m│[0m    👉  https://github.com/kubernetes/minikube/issues/new/choose                           [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯[0m
I0726 09:58:47.517342 3032343 out.go:177] 

* 
* ==> Docker <==
* Jul 26 09:57:38 minikube systemd[1]: Started Docker Application Container Engine.
Jul 26 09:57:38 minikube cri-dockerd[70178]: time="2023-07-26T09:57:38Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"fluentd-vmxds_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"befda206f9da1001fdd6430f86be727fbbeaa24c21ac076ef42a240c35bfa440\""
Jul 26 09:57:38 minikube systemd[1]: Stopping CRI Interface for Docker Application Container Engine...
Jul 26 09:57:38 minikube dockerd[1116670]: time="2023-07-26T09:57:38.910728293Z" level=error msg="Failed to compute size of container rootfs 4f246ffea6eb4369b52f283e93c84ce75267b0f8d5b5b994fcdcb163ca907fc5: mount does not exist"
Jul 26 09:57:39 minikube cri-dockerd[70178]: time="2023-07-26T09:57:39Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"elasticsearch-67468595b7-j9mzq_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"bf202eaf97e17616823f9133fd5d7370419ea69e4e2450ee4fc341517861efc3\""
Jul 26 09:57:39 minikube cri-dockerd[70178]: time="2023-07-26T09:57:39Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"fluentd-ff92m_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"06b9ec04c5bc012242ccea369547fc9a4b3e25baeb1f014b1decb1a1cb973a0a\""
Jul 26 09:57:40 minikube cri-dockerd[70178]: time="2023-07-26T09:57:40Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-5d78c9869d-2sjp8_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"2e994cf22f5d04b6391e63360cdd20f2110003a57bdaaf2fd33aacc96764a24c\""
Jul 26 09:57:40 minikube systemd[1]: cri-docker.service: Deactivated successfully.
Jul 26 09:57:40 minikube systemd[1]: Stopped CRI Interface for Docker Application Container Engine.
Jul 26 09:57:40 minikube dockerd[1116670]: time="2023-07-26T09:57:40.336950193Z" level=error msg="Handler for GET /v1.42/containers/ee6b045bb2dbd8df45f6cc0d8e876f0f27a0b5f3199bdbe946136de24d9d3020/json returned error: write unix /var/run/docker.sock->@: write: broken pipe"
Jul 26 09:57:40 minikube dockerd[1116670]: 2023/07/26 09:57:40 http: superfluous response.WriteHeader call from github.com/docker/docker/api/server/httputils.WriteJSON (httputils.go:92)
Jul 26 09:57:40 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Jul 26 09:57:40 minikube systemd[1]: cri-docker.service: Deactivated successfully.
Jul 26 09:57:40 minikube systemd[1]: Stopped CRI Interface for Docker Application Container Engine.
Jul 26 09:57:40 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Start docker client with request timeout 0s"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Hairpin mode is set to hairpin-veth"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Loaded network plugin cni"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Docker cri networking managed by network plugin cni"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Docker Info: &{ID:dc5e1d5c-9c1c-4a81-88c0-de18682eb47e Containers:44 ContainersRunning:25 ContainersPaused:0 ContainersStopped:19 Images:26 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:false KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:33 OomKillDisable:true NGoroutines:37 SystemTime:2023-07-26T09:57:42.417606921Z LoggingDriver:json-file CgroupDriver:cgroupfs CgroupVersion:1 NEventsListener:0 KernelVersion:5.4.0-81-generic OperatingSystem:Ubuntu 22.04.2 LTS (containerized) OSVersion:22.04 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc000246a80 NCPU:2 MemTotal:4127289344 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy:http://172.16.10.20:3128 HTTPSProxy:http://172.16.10.20:3128 NoProxy:127.0.0.1 Name:minikube Labels:[provider=docker] ExperimentalBuild:false ServerVersion:24.0.4 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:<nil>} runc:{Path:runc Args:[] Shim:<nil>}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil> Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID:v1.1.7-0-g860f061 Expected:v1.1.7-0-g860f061} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin] ProductLicense: DefaultAddressPools:[] Warnings:[WARNING: No swap limit support]}"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Setting cgroupDriver cgroupfs"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Start cri-dockerd grpc backend"
Jul 26 09:57:42 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-mysql-c7b7fcc69-k6h2p_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"2c9822948f76007503ef55d919a8926c97c17fb129424596d2bbac4724e1620e\""
Jul 26 09:57:42 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:42Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-mysql-c7b7fcc69-k6h2p_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"56cf90622c25ac807114fcf4f5cfc0253569e6d546d8307fb4f6758f921428c4\""
Jul 26 09:57:43 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:43Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"kibana-79c4f7d4c8-k7xpv_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"7033f697bd51db07d6c8c69716793fbf1b90c0f6875530897064a95d6296ce09\""
Jul 26 09:57:43 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:43Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"kibana-79c4f7d4c8-k7xpv_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"f7624e75c2dd2e19c5b96e168c285e1875c9da8c268bb239d182378d5028e873\""
Jul 26 09:57:43 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:43Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-b979fc4c6-zfcwm_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"925add63b2f814c37086d34823b7833b4ba689f97f0b111c320ec6efb3a748b5\""
Jul 26 09:57:44 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:43Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-b979fc4c6-zfcwm_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"f3ee995779d798ff41f3b1517ad3529946e3ec3c307d010a84a864b897af7a28\""
Jul 26 09:57:45 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:45Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-mysql-c7b7fcc69-k6h2p_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"2c9822948f76007503ef55d919a8926c97c17fb129424596d2bbac4724e1620e\""
Jul 26 09:57:45 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:45Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"wordpress-mysql-c7b7fcc69-k6h2p_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"56cf90622c25ac807114fcf4f5cfc0253569e6d546d8307fb4f6758f921428c4\""
Jul 26 09:57:46 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:46Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"elasticsearch-67468595b7-j9mzq_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"bf202eaf97e17616823f9133fd5d7370419ea69e4e2450ee4fc341517861efc3\""
Jul 26 09:57:46 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:46Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"elasticsearch-67468595b7-j9mzq_logging\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"cedd17c3cbc26fc2d2122854591dcbb3a56708ff9600822c4ab674b3dd1027c4\""
Jul 26 09:57:46 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:46Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-5d78c9869d-2sjp8_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"ffe1eff7c92a00fcacc617c77b0541970939b2b81d15671cec48528c17d168bb\""
Jul 26 09:57:50 minikube dockerd[1116670]: time="2023-07-26T09:57:50.831585868Z" level=error msg="Failed to compute size of container rootfs a9062725ec4de9f8afaab996956f467061dbbf4044a149b0ba6c8fc18344787f: mount does not exist"
Jul 26 09:57:54 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:54Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a12578882722b3b6582e36a1dd4c85beb727f32d45f07294b071ea3c9b974510/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Jul 26 09:57:54 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:54Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/4b749e93ce10f1acc2a086c7c559007d820d87a2f34445a5765c2e2fb777aef4/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:54 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:54Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/7d1803c4239d60da3891bef45d0427728f95051678c6f2a7ec0cbe626a8e0086/resolv.conf as [nameserver 10.96.0.10 search logging.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:54 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:54Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/7bb19f583753fb09a61d0707d24b53b53f81a7d891c03d5b6791d65949dbe450/resolv.conf as [nameserver 192.168.49.1 options trust-ad ndots:0 edns0]"
Jul 26 09:57:55 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/3e9fdb7f9dfa9fbca2c198c23f54f118357809f2e85038580a696b8f9759ea0b/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Jul 26 09:57:55 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/fa2f84d03a2834ed91054aca34a32e8a0d0bee9d328809bffe688a56a548821f/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:55 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1f1a63feccfac027ddeac424bf0f2213d6b017757fde995e5e3ffc481cb84af7/resolv.conf as [nameserver 10.96.0.10 search logging.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:55 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/11f9e325952dcb92ed0d07d84bf73635185cd200b22c55b10b995e3896739d6c/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Jul 26 09:57:55 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/90c71e634f752f5a8d1c45b2aa84a0ab8d4c72554cffdc181c78b13926d08788/resolv.conf as [nameserver 192.168.49.1 options trust-ad ndots:0 edns0]"
Jul 26 09:57:56 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c055d6e41237588b0933bfe61649c06466cc7da5b3296d50ef3a2b2f3cf74b0f/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Jul 26 09:57:56 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9020d26e73507e7a217c477e0a7ce8907d3c926501bef75b68b3196fece1f26a/resolv.conf as [nameserver 192.168.49.1 options edns0 trust-ad ndots:0]"
Jul 26 09:57:56 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/69f02501c44988ee2e55dfac0b135224f5a4fa6e8e02c97f598ba9652fdc9ce7/resolv.conf as [nameserver 10.96.0.10 search logging.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:56 minikube cri-dockerd[1117297]: time="2023-07-26T09:57:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ec3c9e8efb2c5b3c30dc949b48b3413729a24aeb20765cbff3eea95673be8f4d/resolv.conf as [nameserver 10.96.0.10 search kube-system.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Jul 26 09:57:59 minikube dockerd[1116670]: time="2023-07-26T09:57:59.377698741Z" level=warning msg="Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap."
Jul 26 09:58:00 minikube dockerd[1116670]: time="2023-07-26T09:58:00.034202182Z" level=warning msg="Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap."
Jul 26 09:58:00 minikube dockerd[1116670]: time="2023-07-26T09:58:00.035824849Z" level=warning msg="Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap."
Jul 26 09:58:13 minikube dockerd[1116670]: time="2023-07-26T09:58:13.180995356Z" level=info msg="ignoring event" container=7a50557f99abe2eccbb0d40b3ec70712e5d8c95c43a929cf1b4398e39c06531e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 26 09:58:56 minikube dockerd[1116670]: time="2023-07-26T09:58:56.038597549Z" level=info msg="ignoring event" container=70bda415789a66d32e63f337139d3949e15a38298248c0bcddbd242d291e3e86 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 26 09:59:03 minikube dockerd[1116670]: time="2023-07-26T09:59:03.617801581Z" level=info msg="ignoring event" container=998d2c1540b696a3ab2209380f9987059709a712e42ce4d488725e4bba03d950 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 26 09:59:04 minikube dockerd[1116670]: time="2023-07-26T09:59:04.713420997Z" level=info msg="ignoring event" container=60efc284d44cc13f3c21bb16aabc021740de30313d26d795c79458db4049a663 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 26 09:59:30 minikube dockerd[1116670]: time="2023-07-26T09:59:30.837737540Z" level=info msg="ignoring event" container=9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jul 26 09:59:33 minikube dockerd[1116670]: time="2023-07-26T09:59:33.613914937Z" level=error msg="Failed to compute size of container rootfs b14c819ebe40fbe8422acfdc6a68fc321ce41bbd366815cf242b10675f92aa8e: mount does not exist"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED              STATE               NAME                      ATTEMPT             POD ID              POD
41869e2ce5adc       7cffc01dba0e1       59 seconds ago       Running             kube-controller-manager   17                  11f9e325952dc       kube-controller-manager-minikube
2f9bb18d7c1dd       6e38f40d628db       About a minute ago   Running             storage-provisioner       31                  9020d26e73507       storage-provisioner
156ea058691fc       08a0c939e61b7       About a minute ago   Running             kube-apiserver            16                  3e9fdb7f9dfa9       kube-apiserver-minikube
70bda415789a6       6e38f40d628db       About a minute ago   Exited              storage-provisioner       30                  9020d26e73507       storage-provisioner
9b18ebf6febf7       4654ba3359c97       2 minutes ago        Exited              fluentd                   207                 ec3c9e8efb2c5       fluentd-vmxds
28f788cb0bf0f       ead0a4a53df89       2 minutes ago        Running             coredns                   12                  7bb19f583753f       coredns-5d78c9869d-2sjp8
02cc8b1f1eb1f       fa601f7c24cb4       2 minutes ago        Running             elasticsearch             12                  7d1803c4239d6       elasticsearch-67468595b7-j9mzq
afeaafd720213       9871707dda25a       2 minutes ago        Running             kibana                    12                  1f1a63feccfac       kibana-79c4f7d4c8-k7xpv
ee8b186fcb91c       b490e09857081       2 minutes ago        Running             fluentd                   5                   69f02501c4498       fluentd-ff92m
83ed7fbcea2b6       86b6af7dd652c       2 minutes ago        Running             etcd                      14                  c055d6e412375       etcd-minikube
08b9e941b48de       41697ceeb70b3       2 minutes ago        Running             kube-scheduler            14                  90c71e634f752       kube-scheduler-minikube
64a3db268087f       5780543258cf0       2 minutes ago        Running             kube-proxy                13                  a12578882722b       kube-proxy-xs8fq
998d2c1540b69       08a0c939e61b7       2 minutes ago        Exited              kube-apiserver            15                  3e9fdb7f9dfa9       kube-apiserver-minikube
60efc284d44cc       7cffc01dba0e1       2 minutes ago        Exited              kube-controller-manager   16                  11f9e325952dc       kube-controller-manager-minikube
d0b1b0ee8219d       f6360852d6546       15 hours ago         Exited              mysql                     4                   2c9822948f760       wordpress-mysql-c7b7fcc69-k6h2p
178a7de664be0       b8ee07adfa917       15 hours ago         Exited              wordpress                 4                   925add63b2f81       wordpress-b979fc4c6-zfcwm
f3876bdded8cb       ead0a4a53df89       16 hours ago         Exited              coredns                   11                  2e994cf22f5d0       coredns-5d78c9869d-2sjp8
8291b08c522fe       fa601f7c24cb4       16 hours ago         Exited              elasticsearch             11                  bf202eaf97e17       elasticsearch-67468595b7-j9mzq
34e3bacf124dc       5780543258cf0       16 hours ago         Exited              kube-proxy                12                  d1e71020872d4       kube-proxy-xs8fq
9ed8bf14ca1d8       9871707dda25a       16 hours ago         Exited              kibana                    11                  7033f697bd51d       kibana-79c4f7d4c8-k7xpv
60eb630c6ac41       b490e09857081       16 hours ago         Exited              fluentd                   4                   06b9ec04c5bc0       fluentd-ff92m
4aaae4c4f5201       41697ceeb70b3       16 hours ago         Exited              kube-scheduler            13                  fb8d551674ccb       kube-scheduler-minikube
43f6b91731235       86b6af7dd652c       16 hours ago         Exited              etcd                      13                  c1d6014861121       etcd-minikube

* 
* ==> coredns [28f788cb0bf0] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 05e3eaddc414b2d71a69b2e2bc6f2681fc1f4d04bcdd3acc1a41457bb7db518208b95ddfc4c9fffedc59c25a8faf458be1af4915a4a3c0d6777cb7a346bc5d86
CoreDNS-1.10.1
linux/amd64, go1.20, 055b2c3
[INFO] 127.0.0.1:46326 - 43561 "HINFO IN 9030156765552321442.3351165292030764726. udp 57 false 512" NXDOMAIN qr,rd,ra 57 0.113326361s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": dial tcp 10.96.0.1:443: connect: connection refused
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": dial tcp 10.96.0.1:443: connect: connection refused
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": dial tcp 10.96.0.1:443: connect: connection refused
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: Get "https://10.96.0.1:443/version": dial tcp 10.96.0.1:443: connect: connection refused
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[WARNING] plugin/kubernetes: Kubernetes API connection failure: unknown

* 
* ==> coredns [f3876bdded8c] <==
* [INFO] 10.244.0.156:52389 - 61104 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000062604s
[INFO] 10.244.0.156:38371 - 35866 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000128551s
[INFO] 10.244.0.156:52947 - 47035 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.00006882s
[INFO] 10.244.0.156:40453 - 31170 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000132159s
[INFO] 10.244.0.156:41971 - 18140 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000067411s
[INFO] 10.244.0.156:52767 - 43463 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000062222s
[INFO] 10.244.0.156:50378 - 3122 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000123346s
[INFO] 10.244.0.156:35256 - 719 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000082885s
[INFO] 10.244.0.156:47984 - 21141 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000058082s
[INFO] 10.244.0.156:40950 - 37575 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000066641s
[INFO] 10.244.0.156:46865 - 40444 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000137234s
[INFO] 10.244.0.156:46195 - 13405 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.0000925s
[INFO] 10.244.0.156:36635 - 12495 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000072812s
[INFO] 10.244.0.156:48375 - 18548 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000055039s
[INFO] 10.244.0.156:38875 - 14148 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000043272s
[INFO] 10.244.0.156:59942 - 47544 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000165671s
[INFO] 10.244.0.156:56302 - 49168 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000052526s
[INFO] 10.244.0.156:50644 - 44873 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.00005209s
[INFO] 10.244.0.156:59623 - 36947 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000065505s
[INFO] 10.244.0.156:36271 - 31821 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000089146s
[INFO] 10.244.0.156:59859 - 49312 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000140585s
[INFO] 10.244.0.156:53759 - 9152 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000067536s
[INFO] 10.244.0.156:39439 - 36824 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000064736s
[INFO] 10.244.0.156:34844 - 24894 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000176393s
[INFO] 10.244.0.156:51195 - 194 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000062862s
[INFO] 10.244.0.156:36770 - 20562 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000077974s
[INFO] 10.244.0.156:56731 - 56011 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000057892s
[INFO] 10.244.0.156:51680 - 29987 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000108783s
[INFO] 10.244.0.156:38672 - 28521 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000138389s
[INFO] 10.244.0.156:44254 - 35899 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000088417s
[INFO] 10.244.0.156:54448 - 31003 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.0000755s
[INFO] 10.244.0.156:39457 - 615 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000149139s
[INFO] 10.244.0.156:47109 - 19315 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000050732s
[INFO] 10.244.0.156:60746 - 47413 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000073659s
[INFO] 10.244.0.156:54542 - 28950 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000068151s
[INFO] 10.244.0.156:38512 - 46143 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000090792s
[INFO] 10.244.0.156:32883 - 30139 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000149024s
[INFO] 10.244.0.156:34929 - 30182 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000076765s
[INFO] 10.244.0.156:49385 - 45926 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000064529s
[INFO] 10.244.0.156:36676 - 58730 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000086552s
[INFO] 10.244.0.156:56165 - 52252 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000140526s
[INFO] 10.244.0.156:58839 - 40693 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000057808s
[INFO] 10.244.0.156:37385 - 48735 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000037701s
[INFO] 10.244.0.156:43077 - 56658 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000112474s
[INFO] 10.244.0.156:38472 - 44000 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000158075s
[INFO] 10.244.0.156:51416 - 61358 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000057575s
[INFO] 10.244.0.156:36587 - 9324 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000050526s
[INFO] 10.244.0.156:51159 - 53924 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.0001585s
[INFO] 10.244.0.156:43666 - 10828 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000055581s
[INFO] 10.244.0.156:37550 - 21738 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.00003765s
[INFO] 10.244.0.156:51008 - 6886 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000075075s
[INFO] 10.244.0.156:54912 - 6454 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000106412s
[INFO] 10.244.0.156:52457 - 23174 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000165153s
[INFO] 10.244.0.156:33563 - 21157 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000051454s
[INFO] 10.244.0.156:37979 - 5117 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.0000972s
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.805786425s
[INFO] 10.244.0.156:55040 - 42129 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000084602s
[INFO] 10.244.0.156:44065 - 49743 "A IN elasticsearch.logging.svc.cluster.local. udp 57 false 512" NOERROR qr,aa,rd 112 0.000121018s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=fd3f3801765d093a485d255043149f92ec0a695f
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_07_24T17_24_36_0700
                    minikube.k8s.io/version=v1.31.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Mon, 24 Jul 2023 17:24:33 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 26 Jul 2023 10:00:34 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 26 Jul 2023 09:59:32 +0000   Tue, 25 Jul 2023 18:01:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 26 Jul 2023 09:59:32 +0000   Tue, 25 Jul 2023 18:01:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 26 Jul 2023 09:59:32 +0000   Tue, 25 Jul 2023 18:01:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 26 Jul 2023 09:59:32 +0000   Wed, 26 Jul 2023 09:59:32 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  20511312Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             4030556Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  20511312Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             4030556Ki
  pods:               110
System Info:
  Machine ID:                 2e0fcadc027c4abca46d81d6c43a1062
  System UUID:                df0e6a95-6d89-4aee-aea2-07448c269fbc
  Boot ID:                    ad52be56-4f3d-4236-b7fc-bfaa2a5ea328
  Kernel Version:             5.4.0-81-generic
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.3
  Kube-Proxy Version:         v1.27.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (13 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  default                     wordpress-b979fc4c6-zfcwm           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17h
  default                     wordpress-mysql-c7b7fcc69-k6h2p     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17h
  kube-system                 coredns-5d78c9869d-2sjp8            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     40h
  kube-system                 etcd-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         40h
  kube-system                 fluentd-vmxds                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17h
  kube-system                 kube-apiserver-minikube             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         40h
  kube-system                 kube-controller-manager-minikube    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         40h
  kube-system                 kube-proxy-xs8fq                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         40h
  kube-system                 kube-scheduler-minikube             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         40h
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         40h
  logging                     elasticsearch-67468595b7-j9mzq      0 (0%!)(MISSING)        0 (0%!)(MISSING)      2Gi (52%!)(MISSING)        2Gi (52%!)(MISSING)      40h
  logging                     fluentd-ff92m                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17h
  logging                     kibana-79c4f7d4c8-k7xpv             0 (0%!)(MISSING)        0 (0%!)(MISSING)      1Gi (26%!)(MISSING)        1Gi (26%!)(MISSING)      40h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests      Limits
  --------           --------      ------
  cpu                750m (37%!)(MISSING)    0 (0%!)(MISSING)
  memory             3242Mi (82%!)(MISSING)  3242Mi (82%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)        0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)        0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)        0 (0%!)(MISSING)
Events:
  Type    Reason          Age                  From             Message
  ----    ------          ----                 ----             -------
  Normal  Starting        84s                  kube-proxy       
  Normal  NodeNotReady    3m34s (x5 over 16h)  kubelet          Node minikube status is now: NodeNotReady
  Normal  NodeReady       63s (x5 over 16h)    kubelet          Node minikube status is now: NodeReady
  Normal  RegisteredNode  49s                  node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [  +0.000000] Call Trace:
[  +0.000000]  fpu__init_system+0x11f/0x158
[  +0.000000]  ? cpu_set_bug_bits.constprop.0+0x1f9/0x210
[  +0.000000]  early_cpu_init+0x155/0x174
[  +0.000000]  setup_arch+0xcf/0xa2e
[  +0.000000]  ? lockdown_lsm_init+0x21/0x25
[  +0.000000]  start_kernel+0x68/0x56a
[  +0.000000]  ? copy_bootdata+0x1d/0x5d
[  +0.000000]  x86_64_start_reservations+0x24/0x26
[  +0.000000]  x86_64_start_kernel+0x75/0x79
[  +0.000000]  secondary_startup_64+0xa4/0xb0
[  +0.000000] ---[ end trace d530f4ccb39c6cdb ]---
[  +0.000000] CPUID[0d, 00]: eax=000000e7 ebx=00000a80 ecx=00000a80 edx=00000000
[  +0.000000] CPUID[0d, 01]: eax=0000000f ebx=00000a80 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 02]: eax=00000100 ebx=00000240 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 03]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 04]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 05]: eax=00000040 ebx=00000440 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 06]: eax=00000200 ebx=00000480 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 07]: eax=00000400 ebx=00000680 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 08]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 09]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0a]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0b]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0c]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0d]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0e]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 0f]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 10]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 11]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 12]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] CPUID[0d, 13]: eax=00000000 ebx=00000000 ecx=00000000 edx=00000000
[  +0.000000] core: CPUID marked event: 'cpu cycles' unavailable
[  +0.000100] core: CPUID marked event: 'instructions' unavailable
[  +0.000103] core: CPUID marked event: 'bus cycles' unavailable
[  +0.000100] core: CPUID marked event: 'cache references' unavailable
[  +0.000108] core: CPUID marked event: 'cache misses' unavailable
[  +0.000103] core: CPUID marked event: 'branch instructions' unavailable
[  +0.000113] core: CPUID marked event: 'branch misses' unavailable
[  +0.559754] platform eisa.0: EISA: Cannot allocate resource for mainboard
[  +0.000038] platform eisa.0: Cannot allocate resource for EISA slot 1
[  +0.000063] platform eisa.0: Cannot allocate resource for EISA slot 2
[  +0.000035] platform eisa.0: Cannot allocate resource for EISA slot 3
[  +0.000037] platform eisa.0: Cannot allocate resource for EISA slot 4
[  +0.000060] platform eisa.0: Cannot allocate resource for EISA slot 5
[  +0.000036] platform eisa.0: Cannot allocate resource for EISA slot 6
[  +0.000036] platform eisa.0: Cannot allocate resource for EISA slot 7
[  +0.000045] platform eisa.0: Cannot allocate resource for EISA slot 8
[  +0.311542] piix4_smbus 0000:00:07.3: SMBus Host Controller not enabled!
[  +0.604782] sd 32:0:0:0: [sda] Assuming drive cache: write through
[Jul20 19:18] kauditd_printk_skb: 18 callbacks suppressed
[Jul20 19:19] kauditd_printk_skb: 20 callbacks suppressed
[Jul23 00:09] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [CRTC:38:crtc-0] flip_done timed out
[ +10.240005] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [PLANE:34:plane-0] flip_done timed out
[Jul23 09:21] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [CRTC:38:crtc-0] flip_done timed out
[ +10.239931] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [PLANE:34:plane-0] flip_done timed out
[Jul23 22:45] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [CRTC:38:crtc-0] flip_done timed out
[ +10.239884] [drm:drm_atomic_helper_wait_for_dependencies [drm_kms_helper]] *ERROR* [PLANE:34:plane-0] flip_done timed out
[Jul24 16:38] kauditd_printk_skb: 5 callbacks suppressed
[  +1.266160] Started bpfilter

* 
* ==> etcd [43f6b9173123] <==
* {"level":"info","ts":"2023-07-26T09:53:01.192Z","caller":"traceutil/trace.go:171","msg":"trace[23110311] transaction","detail":"{read_only:false; response_revision:125305; number_of_response:1; }","duration":"312.604912ms","start":"2023-07-26T09:53:00.879Z","end":"2023-07-26T09:53:01.192Z","steps":["trace[23110311] 'process raft request'  (duration: 312.262769ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:53:01.192Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:53:00.879Z","time spent":"312.700439ms","remote":"127.0.0.1:43178","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":521,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:125296 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:472 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >"}
{"level":"info","ts":"2023-07-26T09:53:01.192Z","caller":"traceutil/trace.go:171","msg":"trace[959316891] linearizableReadLoop","detail":"{readStateIndex:156216; appliedIndex:156215; }","duration":"157.86275ms","start":"2023-07-26T09:53:01.034Z","end":"2023-07-26T09:53:01.192Z","steps":["trace[959316891] 'read index received'  (duration: 157.743441ms)","trace[959316891] 'applied index is now lower than readState.Index'  (duration: 119.034µs)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T09:53:01.192Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"158.400207ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1113"}
{"level":"info","ts":"2023-07-26T09:53:01.192Z","caller":"traceutil/trace.go:171","msg":"trace[92016417] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:125305; }","duration":"158.424432ms","start":"2023-07-26T09:53:01.034Z","end":"2023-07-26T09:53:01.192Z","steps":["trace[92016417] 'agreement among raft nodes before linearized reading'  (duration: 158.35213ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:53:01.497Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"175.661036ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022671819541380 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125304 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >>","response":"size:18"}
{"level":"info","ts":"2023-07-26T09:53:01.497Z","caller":"traceutil/trace.go:171","msg":"trace[697837575] transaction","detail":"{read_only:false; response_revision:125306; number_of_response:1; }","duration":"301.368452ms","start":"2023-07-26T09:53:01.195Z","end":"2023-07-26T09:53:01.497Z","steps":["trace[697837575] 'process raft request'  (duration: 125.576019ms)","trace[697837575] 'compare'  (duration: 175.411113ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T09:53:01.497Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:53:01.195Z","time spent":"301.415865ms","remote":"127.0.0.1:43148","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1094,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125304 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"warn","ts":"2023-07-26T09:53:01.898Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"122.491732ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2023-07-26T09:53:01.898Z","caller":"traceutil/trace.go:171","msg":"trace[802987069] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:0; response_revision:125306; }","duration":"122.894114ms","start":"2023-07-26T09:53:01.775Z","end":"2023-07-26T09:53:01.898Z","steps":["trace[802987069] 'count revisions from in-memory index tree'  (duration: 122.41077ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:54:38.242Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":125142}
{"level":"info","ts":"2023-07-26T09:54:38.244Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":125142,"took":"698.94µs","hash":1613431829}
{"level":"info","ts":"2023-07-26T09:54:38.244Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":1613431829,"revision":125142,"compact-revision":124899}
{"level":"info","ts":"2023-07-26T09:54:49.014Z","caller":"traceutil/trace.go:171","msg":"trace[2089843841] transaction","detail":"{read_only:false; response_revision:125398; number_of_response:1; }","duration":"383.920252ms","start":"2023-07-26T09:54:48.630Z","end":"2023-07-26T09:54:49.014Z","steps":["trace[2089843841] 'process raft request'  (duration: 383.809827ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:54:49.014Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:54:48.630Z","time spent":"384.106689ms","remote":"127.0.0.1:43150","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":7841,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:125146 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:7807 >> failure:<request_range:<key:\"/registry/minions/minikube\" > >"}
{"level":"info","ts":"2023-07-26T09:54:50.203Z","caller":"traceutil/trace.go:171","msg":"trace[2048138890] transaction","detail":"{read_only:false; response_revision:125399; number_of_response:1; }","duration":"108.856248ms","start":"2023-07-26T09:54:50.094Z","end":"2023-07-26T09:54:50.202Z","steps":["trace[2048138890] 'process raft request'  (duration: 108.75093ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:55:34.076Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:55:33.645Z","time spent":"431.533661ms","remote":"127.0.0.1:43128","response type":"/etcdserverpb.Lease/LeaseGrant","request count":-1,"request size":-1,"response count":-1,"response size":-1,"request content":""}
{"level":"warn","ts":"2023-07-26T09:55:44.858Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"166.502496ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022671819542064 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:125435 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:472 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >>","response":"size:18"}
{"level":"info","ts":"2023-07-26T09:55:44.858Z","caller":"traceutil/trace.go:171","msg":"trace[123342695] transaction","detail":"{read_only:false; response_revision:125443; number_of_response:1; }","duration":"176.185484ms","start":"2023-07-26T09:55:44.682Z","end":"2023-07-26T09:55:44.858Z","steps":["trace[123342695] 'compare'  (duration: 166.425297ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:56:43.214Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"101.810153ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/apiextensions.k8s.io/customresourcedefinitions/\" range_end:\"/registry/apiextensions.k8s.io/customresourcedefinitions0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T09:56:43.214Z","caller":"traceutil/trace.go:171","msg":"trace[1475657588] range","detail":"{range_begin:/registry/apiextensions.k8s.io/customresourcedefinitions/; range_end:/registry/apiextensions.k8s.io/customresourcedefinitions0; response_count:0; response_revision:125488; }","duration":"101.908054ms","start":"2023-07-26T09:56:43.112Z","end":"2023-07-26T09:56:43.214Z","steps":["trace[1475657588] 'count revisions from in-memory index tree'  (duration: 101.684371ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:56:58.835Z","caller":"traceutil/trace.go:171","msg":"trace[1428028110] transaction","detail":"{read_only:false; response_revision:125501; number_of_response:1; }","duration":"136.159752ms","start":"2023-07-26T09:56:58.699Z","end":"2023-07-26T09:56:58.835Z","steps":["trace[1428028110] 'process raft request'  (duration: 136.058772ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:56:59.751Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"220.081811ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022671819542373 > lease_revoke:<id:70cc898e50200f1b>","response":"size:30"}
{"level":"info","ts":"2023-07-26T09:56:59.751Z","caller":"traceutil/trace.go:171","msg":"trace[407236629] linearizableReadLoop","detail":"{readStateIndex:156462; appliedIndex:156461; }","duration":"481.487622ms","start":"2023-07-26T09:56:59.269Z","end":"2023-07-26T09:56:59.751Z","steps":["trace[407236629] 'read index received'  (duration: 261.313308ms)","trace[407236629] 'applied index is now lower than readState.Index'  (duration: 220.173173ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T09:56:59.752Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"482.105272ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T09:56:59.752Z","caller":"traceutil/trace.go:171","msg":"trace[664254008] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:125501; }","duration":"482.148278ms","start":"2023-07-26T09:56:59.269Z","end":"2023-07-26T09:56:59.752Z","steps":["trace[664254008] 'agreement among raft nodes before linearized reading'  (duration: 481.511236ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:56:59.752Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:56:59.269Z","time spent":"482.187889ms","remote":"127.0.0.1:43238","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-07-26T09:56:59.256Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2023-07-26T09:57:00.753Z","caller":"embed/etcd.go:373","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:57:01.946Z","time spent":"754.474262ms","remote":"127.0.0.1:43132","response type":"/etcdserverpb.KV/Txn","request count":0,"request size":0,"response count":0,"response size":0,"request content":""}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"etcdserver/v3_server.go:840","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":8128022671819542378,"retry-timeout":"500ms"}
{"level":"warn","ts":"2023-07-26T09:57:02.701Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:03.043Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:03.043Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.084125408s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2023-07-26T09:57:03.043Z","caller":"traceutil/trace.go:171","msg":"trace[1286218777] range","detail":"{range_begin:/registry/health; range_end:; }","duration":"1.084153829s","start":"2023-07-26T09:57:01.959Z","end":"2023-07-26T09:57:03.043Z","steps":["trace[1286218777] 'agreement among raft nodes before linearized reading'  (duration: 1.084104434s)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:57:03.043Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:57:01.959Z","time spent":"1.084182923s","remote":"127.0.0.1:43238","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":0,"request content":"key:\"/registry/health\" "}
WARNING: 2023/07/26 09:57:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2023-07-26T09:57:03.054Z","caller":"wal/wal.go:805","msg":"slow fdatasync","took":"1.108013565s","expected-duration":"1s"}
{"level":"warn","ts":"2023-07-26T09:57:03.055Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:03.055Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:02.561Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
{"level":"warn","ts":"2023-07-26T09:57:02.562Z","caller":"v3rpc/watch.go:457","msg":"failed to send watch response to gRPC stream","error":"rpc error: code = Unavailable desc = transport is closing"}
WARNING: 2023/07/26 09:57:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2023-07-26T09:57:03.206Z","caller":"etcdserver/v3_server.go:840","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":8128022671819542378,"retry-timeout":"500ms"}
{"level":"warn","ts":"2023-07-26T09:57:03.234Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.275912425s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/192.168.49.2\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2023-07-26T09:57:03.234Z","caller":"traceutil/trace.go:171","msg":"trace[222222388] range","detail":"{range_begin:/registry/masterleases/192.168.49.2; range_end:; }","duration":"1.275982808s","start":"2023-07-26T09:57:01.958Z","end":"2023-07-26T09:57:03.234Z","steps":["trace[222222388] 'agreement among raft nodes before linearized reading'  (duration: 1.275886922s)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:57:03.234Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:57:01.958Z","time spent":"1.276026405s","remote":"127.0.0.1:43128","response type":"/etcdserverpb.KV/Range","request count":0,"request size":37,"response count":0,"response size":0,"request content":"key:\"/registry/masterleases/192.168.49.2\" "}
WARNING: 2023/07/26 09:57:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2023-07-26T09:57:03.241Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:57:02.042Z","time spent":"1.199765145s","remote":"127.0.0.1:43150","response type":"/etcdserverpb.KV/Txn","request count":0,"request size":0,"response count":0,"response size":0,"request content":""}
WARNING: 2023/07/26 09:57:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2023-07-26T09:57:03.910Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"668.128541ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022671819542381 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/kube-apiserver-minikube.17752c92eb37348a\" mod_revision:0 > success:<request_put:<key:\"/registry/events/kube-system/kube-apiserver-minikube.17752c92eb37348a\" value_size:606 lease:8128022671819542379 >> failure:<>>","response":"size:18"}
{"level":"warn","ts":"2023-07-26T09:57:04.422Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"511.974377ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022671819542382 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/minions/minikube\" mod_revision:125398 > success:<request_put:<key:\"/registry/minions/minikube\" value_size:8002 >> failure:<>>","response":"size:18"}
{"level":"info","ts":"2023-07-26T09:57:04.422Z","caller":"traceutil/trace.go:171","msg":"trace[1842618818] linearizableReadLoop","detail":"{readStateIndex:156465; appliedIndex:156463; }","duration":"2.46358203s","start":"2023-07-26T09:57:01.958Z","end":"2023-07-26T09:57:04.422Z","steps":["trace[1842618818] 'read index received'  (duration: 1.297866476s)","trace[1842618818] 'applied index is now lower than readState.Index'  (duration: 1.165714595s)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:57:05.849Z","caller":"etcdserver/server.go:1465","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2023-07-26T09:57:07.684Z","caller":"embed/etcd.go:568","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-07-26T09:57:07.685Z","caller":"embed/etcd.go:573","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-07-26T09:57:07.685Z","caller":"embed/etcd.go:375","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}

* 
* ==> etcd [83ed7fbcea2b] <==
* {"level":"info","ts":"2023-07-26T09:59:36.341Z","caller":"traceutil/trace.go:171","msg":"trace[2076765857] linearizableReadLoop","detail":"{readStateIndex:156568; appliedIndex:156567; }","duration":"145.226501ms","start":"2023-07-26T09:59:36.196Z","end":"2023-07-26T09:59:36.341Z","steps":["trace[2076765857] 'read index received'  (duration: 145.107448ms)","trace[2076765857] 'applied index is now lower than readState.Index'  (duration: 118.789µs)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:59:36.342Z","caller":"traceutil/trace.go:171","msg":"trace[1266861854] transaction","detail":"{read_only:false; response_revision:125601; number_of_response:1; }","duration":"145.865316ms","start":"2023-07-26T09:59:36.196Z","end":"2023-07-26T09:59:36.342Z","steps":["trace[1266861854] 'process raft request'  (duration: 145.548477ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:36.342Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"145.455866ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/kube-system/kube-controller-manager-minikube\" ","response":"range_response_count:1 size:7155"}
{"level":"info","ts":"2023-07-26T09:59:36.342Z","caller":"traceutil/trace.go:171","msg":"trace[1457492700] range","detail":"{range_begin:/registry/pods/kube-system/kube-controller-manager-minikube; range_end:; response_count:1; response_revision:125601; }","duration":"145.513501ms","start":"2023-07-26T09:59:36.196Z","end":"2023-07-26T09:59:36.342Z","steps":["trace[1457492700] 'agreement among raft nodes before linearized reading'  (duration: 145.304161ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:59:36.527Z","caller":"traceutil/trace.go:171","msg":"trace[1697262439] transaction","detail":"{read_only:false; response_revision:125605; number_of_response:1; }","duration":"133.351522ms","start":"2023-07-26T09:59:36.394Z","end":"2023-07-26T09:59:36.527Z","steps":["trace[1697262439] 'process raft request'  (duration: 133.146097ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:36.888Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"244.406679ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022686105694447 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/pods/kube-system/kube-apiserver-minikube\" mod_revision:125507 > success:<request_put:<key:\"/registry/pods/kube-system/kube-apiserver-minikube\" value_size:7266 >> failure:<request_range:<key:\"/registry/pods/kube-system/kube-apiserver-minikube\" > >>","response":"size:18"}
{"level":"info","ts":"2023-07-26T09:59:36.888Z","caller":"traceutil/trace.go:171","msg":"trace[1354809091] linearizableReadLoop","detail":"{readStateIndex:156573; appliedIndex:156571; }","duration":"380.297953ms","start":"2023-07-26T09:59:36.508Z","end":"2023-07-26T09:59:36.888Z","steps":["trace[1354809091] 'read index received'  (duration: 19.087516ms)","trace[1354809091] 'applied index is now lower than readState.Index'  (duration: 361.209273ms)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:59:36.888Z","caller":"traceutil/trace.go:171","msg":"trace[280643179] transaction","detail":"{read_only:false; response_revision:125606; number_of_response:1; }","duration":"490.457722ms","start":"2023-07-26T09:59:36.398Z","end":"2023-07-26T09:59:36.888Z","steps":["trace[280643179] 'process raft request'  (duration: 245.52466ms)","trace[280643179] 'compare'  (duration: 244.295795ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T09:59:36.889Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:59:36.398Z","time spent":"490.58557ms","remote":"127.0.0.1:33102","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":7324,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/pods/kube-system/kube-apiserver-minikube\" mod_revision:125507 > success:<request_put:<key:\"/registry/pods/kube-system/kube-apiserver-minikube\" value_size:7266 >> failure:<request_range:<key:\"/registry/pods/kube-system/kube-apiserver-minikube\" > >"}
{"level":"warn","ts":"2023-07-26T09:59:36.889Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"381.133099ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1113"}
{"level":"info","ts":"2023-07-26T09:59:36.890Z","caller":"traceutil/trace.go:171","msg":"trace[491211260] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:125606; }","duration":"381.942506ms","start":"2023-07-26T09:59:36.508Z","end":"2023-07-26T09:59:36.890Z","steps":["trace[491211260] 'agreement among raft nodes before linearized reading'  (duration: 381.099057ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:36.889Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"359.448628ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/logging/fluentd-ff92m.17752c609dafdbdb\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T09:59:36.890Z","caller":"traceutil/trace.go:171","msg":"trace[1066206667] range","detail":"{range_begin:/registry/events/logging/fluentd-ff92m.17752c609dafdbdb; range_end:; response_count:0; response_revision:125606; }","duration":"360.340564ms","start":"2023-07-26T09:59:36.530Z","end":"2023-07-26T09:59:36.890Z","steps":["trace[1066206667] 'agreement among raft nodes before linearized reading'  (duration: 358.880592ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:36.890Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:59:36.530Z","time spent":"360.406696ms","remote":"127.0.0.1:33078","response type":"/etcdserverpb.KV/Range","request count":0,"request size":57,"response count":0,"response size":30,"request content":"key:\"/registry/events/logging/fluentd-ff92m.17752c609dafdbdb\" "}
{"level":"warn","ts":"2023-07-26T09:59:36.890Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:59:36.508Z","time spent":"382.077759ms","remote":"127.0.0.1:33094","response type":"/etcdserverpb.KV/Range","request count":0,"request size":67,"response count":1,"response size":1137,"request content":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" "}
{"level":"info","ts":"2023-07-26T09:59:37.079Z","caller":"traceutil/trace.go:171","msg":"trace[55453580] transaction","detail":"{read_only:false; response_revision:125612; number_of_response:1; }","duration":"108.809637ms","start":"2023-07-26T09:59:36.970Z","end":"2023-07-26T09:59:37.079Z","steps":["trace[55453580] 'process raft request'  (duration: 18.074802ms)","trace[55453580] 'compare'  (duration: 90.644235ms)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:59:38.322Z","caller":"traceutil/trace.go:171","msg":"trace[1949273750] transaction","detail":"{read_only:false; response_revision:125675; number_of_response:1; }","duration":"161.257471ms","start":"2023-07-26T09:59:38.161Z","end":"2023-07-26T09:59:38.322Z","steps":["trace[1949273750] 'process raft request'  (duration: 161.178872ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:59:44.440Z","caller":"traceutil/trace.go:171","msg":"trace[1829026281] linearizableReadLoop","detail":"{readStateIndex:156648; appliedIndex:156647; }","duration":"183.07086ms","start":"2023-07-26T09:59:44.257Z","end":"2023-07-26T09:59:44.440Z","steps":["trace[1829026281] 'read index received'  (duration: 182.965023ms)","trace[1829026281] 'applied index is now lower than readState.Index'  (duration: 105.461µs)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:59:44.440Z","caller":"traceutil/trace.go:171","msg":"trace[1563712380] transaction","detail":"{read_only:false; response_revision:125681; number_of_response:1; }","duration":"231.608495ms","start":"2023-07-26T09:59:44.208Z","end":"2023-07-26T09:59:44.440Z","steps":["trace[1563712380] 'process raft request'  (duration: 231.454187ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:44.440Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"183.244318ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T09:59:44.440Z","caller":"traceutil/trace.go:171","msg":"trace[1986744946] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:125681; }","duration":"183.271075ms","start":"2023-07-26T09:59:44.257Z","end":"2023-07-26T09:59:44.440Z","steps":["trace[1986744946] 'agreement among raft nodes before linearized reading'  (duration: 183.211997ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:59:46.578Z","caller":"traceutil/trace.go:171","msg":"trace[1271797029] transaction","detail":"{read_only:false; response_revision:125697; number_of_response:1; }","duration":"129.68302ms","start":"2023-07-26T09:59:46.449Z","end":"2023-07-26T09:59:46.578Z","steps":["trace[1271797029] 'process raft request'  (duration: 66.852563ms)","trace[1271797029] 'compare'  (duration: 62.757114ms)"],"step_count":2}
{"level":"info","ts":"2023-07-26T09:59:46.598Z","caller":"traceutil/trace.go:171","msg":"trace[1247342617] transaction","detail":"{read_only:false; response_revision:125698; number_of_response:1; }","duration":"149.513189ms","start":"2023-07-26T09:59:46.449Z","end":"2023-07-26T09:59:46.598Z","steps":["trace[1247342617] 'process raft request'  (duration: 149.395449ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T09:59:52.271Z","caller":"traceutil/trace.go:171","msg":"trace[425696958] transaction","detail":"{read_only:false; response_revision:125700; number_of_response:1; }","duration":"160.313784ms","start":"2023-07-26T09:59:52.110Z","end":"2023-07-26T09:59:52.271Z","steps":["trace[425696958] 'process raft request'  (duration: 160.006174ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T09:59:52.620Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"242.477456ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022686105694738 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125700 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >>","response":"size:18"}
{"level":"info","ts":"2023-07-26T09:59:52.620Z","caller":"traceutil/trace.go:171","msg":"trace[885125270] transaction","detail":"{read_only:false; response_revision:125702; number_of_response:1; }","duration":"344.291298ms","start":"2023-07-26T09:59:52.276Z","end":"2023-07-26T09:59:52.620Z","steps":["trace[885125270] 'process raft request'  (duration: 101.690756ms)","trace[885125270] 'compare'  (duration: 242.395702ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T09:59:52.620Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T09:59:52.276Z","time spent":"344.466485ms","remote":"127.0.0.1:33094","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1094,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125700 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"warn","ts":"2023-07-26T10:00:01.325Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"109.01632ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumeclaims/default/wp-pv-claim\" ","response":"range_response_count:1 size:1686"}
{"level":"info","ts":"2023-07-26T10:00:01.325Z","caller":"traceutil/trace.go:171","msg":"trace[1571241504] range","detail":"{range_begin:/registry/persistentvolumeclaims/default/wp-pv-claim; range_end:; response_count:1; response_revision:125712; }","duration":"109.114136ms","start":"2023-07-26T10:00:01.216Z","end":"2023-07-26T10:00:01.325Z","steps":["trace[1571241504] 'range keys from in-memory index tree'  (duration: 108.802261ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:03.665Z","caller":"traceutil/trace.go:171","msg":"trace[1525853368] transaction","detail":"{read_only:false; response_revision:125715; number_of_response:1; }","duration":"263.655085ms","start":"2023-07-26T10:00:03.401Z","end":"2023-07-26T10:00:03.665Z","steps":["trace[1525853368] 'process raft request'  (duration: 263.563648ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:06.038Z","caller":"traceutil/trace.go:171","msg":"trace[1101501585] transaction","detail":"{read_only:false; response_revision:125718; number_of_response:1; }","duration":"233.741554ms","start":"2023-07-26T10:00:05.805Z","end":"2023-07-26T10:00:06.038Z","steps":["trace[1101501585] 'process raft request'  (duration: 233.400951ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T10:00:06.424Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"160.170142ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T10:00:06.425Z","caller":"traceutil/trace.go:171","msg":"trace[1333826684] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:125718; }","duration":"160.384095ms","start":"2023-07-26T10:00:06.264Z","end":"2023-07-26T10:00:06.424Z","steps":["trace[1333826684] 'range keys from in-memory index tree'  (duration: 160.064309ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:08.315Z","caller":"traceutil/trace.go:171","msg":"trace[1824726477] transaction","detail":"{read_only:false; response_revision:125719; number_of_response:1; }","duration":"142.435604ms","start":"2023-07-26T10:00:08.172Z","end":"2023-07-26T10:00:08.315Z","steps":["trace[1824726477] 'process raft request'  (duration: 142.070036ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:12.362Z","caller":"traceutil/trace.go:171","msg":"trace[1437871402] linearizableReadLoop","detail":"{readStateIndex:156696; appliedIndex:156695; }","duration":"166.634552ms","start":"2023-07-26T10:00:12.196Z","end":"2023-07-26T10:00:12.362Z","steps":["trace[1437871402] 'read index received'  (duration: 90.543925ms)","trace[1437871402] 'applied index is now lower than readState.Index'  (duration: 76.090314ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:12.363Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"166.915182ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumeclaims/default/mysql-pv-claim\" ","response":"range_response_count:1 size:1695"}
{"level":"info","ts":"2023-07-26T10:00:12.363Z","caller":"traceutil/trace.go:171","msg":"trace[688924680] range","detail":"{range_begin:/registry/persistentvolumeclaims/default/mysql-pv-claim; range_end:; response_count:1; response_revision:125722; }","duration":"166.957744ms","start":"2023-07-26T10:00:12.196Z","end":"2023-07-26T10:00:12.363Z","steps":["trace[688924680] 'agreement among raft nodes before linearized reading'  (duration: 166.836605ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:12.363Z","caller":"traceutil/trace.go:171","msg":"trace[1453999660] transaction","detail":"{read_only:false; response_revision:125722; number_of_response:1; }","duration":"233.206944ms","start":"2023-07-26T10:00:12.130Z","end":"2023-07-26T10:00:12.363Z","steps":["trace[1453999660] 'process raft request'  (duration: 156.567409ms)","trace[1453999660] 'compare'  (duration: 75.986949ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:12.363Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"107.153611ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T10:00:12.363Z","caller":"traceutil/trace.go:171","msg":"trace[1121722597] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:125722; }","duration":"107.180032ms","start":"2023-07-26T10:00:12.256Z","end":"2023-07-26T10:00:12.363Z","steps":["trace[1121722597] 'agreement among raft nodes before linearized reading'  (duration: 107.131319ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T10:00:17.927Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"516.491039ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128022686105694848 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125727 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >>","response":"size:18"}
{"level":"info","ts":"2023-07-26T10:00:17.927Z","caller":"traceutil/trace.go:171","msg":"trace[2038151953] linearizableReadLoop","detail":"{readStateIndex:156705; appliedIndex:156704; }","duration":"670.652537ms","start":"2023-07-26T10:00:17.257Z","end":"2023-07-26T10:00:17.927Z","steps":["trace[2038151953] 'read index received'  (duration: 154.043019ms)","trace[2038151953] 'applied index is now lower than readState.Index'  (duration: 516.608973ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:17.927Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"670.736481ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-07-26T10:00:17.927Z","caller":"traceutil/trace.go:171","msg":"trace[1867480676] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:125730; }","duration":"670.756435ms","start":"2023-07-26T10:00:17.257Z","end":"2023-07-26T10:00:17.927Z","steps":["trace[1867480676] 'agreement among raft nodes before linearized reading'  (duration: 670.684444ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T10:00:17.927Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T10:00:17.257Z","time spent":"670.784922ms","remote":"127.0.0.1:33030","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"info","ts":"2023-07-26T10:00:17.928Z","caller":"traceutil/trace.go:171","msg":"trace[745730097] transaction","detail":"{read_only:false; response_revision:125730; number_of_response:1; }","duration":"683.339151ms","start":"2023-07-26T10:00:17.245Z","end":"2023-07-26T10:00:17.928Z","steps":["trace[745730097] 'process raft request'  (duration: 166.034245ms)","trace[745730097] 'compare'  (duration: 516.412025ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:17.928Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T10:00:17.245Z","time spent":"683.390885ms","remote":"127.0.0.1:33094","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1094,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:125727 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"info","ts":"2023-07-26T10:00:24.490Z","caller":"traceutil/trace.go:171","msg":"trace[1370862119] linearizableReadLoop","detail":"{readStateIndex:156711; appliedIndex:156710; }","duration":"106.088438ms","start":"2023-07-26T10:00:24.384Z","end":"2023-07-26T10:00:24.490Z","steps":["trace[1370862119] 'read index received'  (duration: 105.984961ms)","trace[1370862119] 'applied index is now lower than readState.Index'  (duration: 103.205µs)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:24.490Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"106.198666ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/namespaces/default\" ","response":"range_response_count:1 size:340"}
{"level":"info","ts":"2023-07-26T10:00:24.490Z","caller":"traceutil/trace.go:171","msg":"trace[1805510035] range","detail":"{range_begin:/registry/namespaces/default; range_end:; response_count:1; response_revision:125735; }","duration":"106.230112ms","start":"2023-07-26T10:00:24.384Z","end":"2023-07-26T10:00:24.490Z","steps":["trace[1805510035] 'agreement among raft nodes before linearized reading'  (duration: 106.142106ms)"],"step_count":1}
{"level":"info","ts":"2023-07-26T10:00:24.491Z","caller":"traceutil/trace.go:171","msg":"trace[461662118] transaction","detail":"{read_only:false; response_revision:125735; number_of_response:1; }","duration":"338.071974ms","start":"2023-07-26T10:00:24.152Z","end":"2023-07-26T10:00:24.491Z","steps":["trace[461662118] 'process raft request'  (duration: 337.668146ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T10:00:24.491Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T10:00:24.152Z","time spent":"338.106911ms","remote":"127.0.0.1:33124","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":672,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:125725 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:599 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >"}
{"level":"warn","ts":"2023-07-26T10:00:32.689Z","caller":"etcdserver/v3_server.go:840","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":8128022686105694906,"retry-timeout":"500ms"}
{"level":"info","ts":"2023-07-26T10:00:32.712Z","caller":"traceutil/trace.go:171","msg":"trace[410433583] transaction","detail":"{read_only:false; response_revision:125744; number_of_response:1; }","duration":"581.964333ms","start":"2023-07-26T10:00:32.130Z","end":"2023-07-26T10:00:32.712Z","steps":["trace[410433583] 'process raft request'  (duration: 562.046449ms)","trace[410433583] 'compare'  (duration: 19.487071ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:32.712Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T10:00:32.130Z","time spent":"582.006258ms","remote":"127.0.0.1:33102","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":4104,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/pods/default/wordpress-b979fc4c6-zfcwm\" mod_revision:125728 > success:<request_put:<key:\"/registry/pods/default/wordpress-b979fc4c6-zfcwm\" value_size:4048 >> failure:<request_range:<key:\"/registry/pods/default/wordpress-b979fc4c6-zfcwm\" > >"}
{"level":"info","ts":"2023-07-26T10:00:32.712Z","caller":"traceutil/trace.go:171","msg":"trace[334599440] linearizableReadLoop","detail":"{readStateIndex:156722; appliedIndex:156721; }","duration":"524.29673ms","start":"2023-07-26T10:00:32.188Z","end":"2023-07-26T10:00:32.712Z","steps":["trace[334599440] 'read index received'  (duration: 504.48398ms)","trace[334599440] 'applied index is now lower than readState.Index'  (duration: 19.81238ms)"],"step_count":2}
{"level":"warn","ts":"2023-07-26T10:00:32.714Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"526.65814ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumes/pvc-763c93b8-8450-4723-9dbd-ac8374c92ed6\" ","response":"range_response_count:1 size:1204"}
{"level":"info","ts":"2023-07-26T10:00:32.714Z","caller":"traceutil/trace.go:171","msg":"trace[67702900] range","detail":"{range_begin:/registry/persistentvolumes/pvc-763c93b8-8450-4723-9dbd-ac8374c92ed6; range_end:; response_count:1; response_revision:125744; }","duration":"526.692801ms","start":"2023-07-26T10:00:32.188Z","end":"2023-07-26T10:00:32.714Z","steps":["trace[67702900] 'agreement among raft nodes before linearized reading'  (duration: 526.460733ms)"],"step_count":1}
{"level":"warn","ts":"2023-07-26T10:00:32.715Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-07-26T10:00:32.188Z","time spent":"526.843982ms","remote":"127.0.0.1:33086","response type":"/etcdserverpb.KV/Range","request count":0,"request size":70,"response count":1,"response size":1228,"request content":"key:\"/registry/persistentvolumes/pvc-763c93b8-8450-4723-9dbd-ac8374c92ed6\" "}
{"level":"info","ts":"2023-07-26T10:00:34.759Z","caller":"traceutil/trace.go:171","msg":"trace[443452127] transaction","detail":"{read_only:false; response_revision:125748; number_of_response:1; }","duration":"136.947603ms","start":"2023-07-26T10:00:34.622Z","end":"2023-07-26T10:00:34.759Z","steps":["trace[443452127] 'process raft request'  (duration: 95.245478ms)","trace[443452127] 'compare'  (duration: 41.25588ms)"],"step_count":2}

* 
* ==> kernel <==
*  10:00:36 up 5 days, 18:19,  0 users,  load average: 6.13, 5.19, 2.68
Linux minikube 5.4.0-81-generic #91-Ubuntu SMP Thu Jul 15 19:09:17 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [156ea058691f] <==
* I0726 09:59:31.407748       1 available_controller.go:423] Starting AvailableConditionController
I0726 09:59:31.407843       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0726 09:59:31.407931       1 handler_discovery.go:392] Starting ResourceDiscoveryManager
I0726 09:59:31.408559       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0726 09:59:31.408628       1 shared_informer.go:311] Waiting for caches to sync for cluster_authentication_trust_controller
I0726 09:59:31.408709       1 system_namespaces_controller.go:67] Starting system namespaces controller
I0726 09:59:31.408907       1 controller.go:83] Starting OpenAPI AggregationController
I0726 09:59:31.409167       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0726 09:59:31.409372       1 controller.go:121] Starting legacy_token_tracking_controller
I0726 09:59:31.409441       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I0726 09:59:31.409754       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0726 09:59:31.409874       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0726 09:59:31.409950       1 apf_controller.go:361] Starting API Priority and Fairness config controller
I0726 09:59:31.410228       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0726 09:59:31.410396       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0726 09:59:31.410447       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0726 09:59:31.410516       1 aggregator.go:150] waiting for initial CRD sync...
I0726 09:59:31.410594       1 controller.go:85] Starting OpenAPI controller
I0726 09:59:31.410679       1 controller.go:85] Starting OpenAPI V3 controller
I0726 09:59:31.410741       1 naming_controller.go:291] Starting NamingConditionController
I0726 09:59:31.410807       1 establishing_controller.go:76] Starting EstablishingController
I0726 09:59:31.410877       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0726 09:59:31.410950       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0726 09:59:31.411009       1 crd_finalizer.go:266] Starting CRDFinalizer
I0726 09:59:31.595483       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0726 09:59:31.595662       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
I0726 09:59:31.597638       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0726 09:59:31.597818       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0726 09:59:32.080405       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
E0726 09:59:32.642316       1 controller.go:155] Error removing old endpoints from kubernetes service: no master IPs were listed in storage, refusing to erase all endpoints for the kubernetes service
I0726 09:59:32.643514       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0726 09:59:32.697074       1 shared_informer.go:318] Caches are synced for crd-autoregister
I0726 09:59:32.697677       1 aggregator.go:152] initial CRD sync complete...
I0726 09:59:32.698091       1 autoregister_controller.go:141] Starting autoregister controller
I0726 09:59:32.698173       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0726 09:59:32.698227       1 cache.go:39] Caches are synced for autoregister controller
I0726 09:59:32.707052       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0726 09:59:32.708646       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0726 09:59:32.708743       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I0726 09:59:32.709640       1 shared_informer.go:318] Caches are synced for configmaps
I0726 09:59:32.710449       1 apf_controller.go:366] Running API Priority and Fairness config worker
I0726 09:59:32.710511       1 apf_controller.go:369] Running API Priority and Fairness periodic rebalancing process
I0726 09:59:32.710583       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0726 09:59:32.712518       1 shared_informer.go:318] Caches are synced for node_authorizer
I0726 09:59:46.252865       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0726 09:59:46.325315       1 controller.go:624] quota admission added evaluator for: endpoints
I0726 10:00:02.761005       1 trace.go:219] Trace[2133528640]: "DeltaFIFO Pop Process" ID:v1.coordination.k8s.io,Depth:18,Reason:slow event handlers blocking the queue (26-Jul-2023 10:00:02.635) (total time: 125ms):
Trace[2133528640]: [125.287764ms] [125.287764ms] END
I0726 10:00:17.929193       1 trace.go:219] Trace[1894655783]: "Update" accept:application/json, */*,audit-id:93e7a45f-460a-408c-b4a2-82e075aca529,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (26-Jul-2023 10:00:17.243) (total time: 685ms):
Trace[1894655783]: ["GuaranteedUpdate etcd3" audit-id:93e7a45f-460a-408c-b4a2-82e075aca529,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 684ms (10:00:17.244)
Trace[1894655783]:  ---"Txn call completed" 684ms (10:00:17.929)]
Trace[1894655783]: [685.34828ms] [685.34828ms] END
I0726 10:00:32.715246       1 trace.go:219] Trace[1698545580]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:0bed7a96-1073-414a-913d-828f9a94e135,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/default/pods/wordpress-b979fc4c6-zfcwm/status,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:PATCH (26-Jul-2023 10:00:32.128) (total time: 586ms):
Trace[1698545580]: ["GuaranteedUpdate etcd3" audit-id:0bed7a96-1073-414a-913d-828f9a94e135,key:/pods/default/wordpress-b979fc4c6-zfcwm,type:*core.Pod,resource:pods 586ms (10:00:32.128)
Trace[1698545580]:  ---"Txn call completed" 584ms (10:00:32.714)]
Trace[1698545580]: ---"Object stored in database" 584ms (10:00:32.715)
Trace[1698545580]: [586.69292ms] [586.69292ms] END
I0726 10:00:32.716567       1 trace.go:219] Trace[1098989215]: "Get" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:b454f301-58e3-41d8-b8ec-0172c4d21e28,client:192.168.49.2,protocol:HTTP/2.0,resource:persistentvolumes,scope:resource,url:/api/v1/persistentvolumes/pvc-763c93b8-8450-4723-9dbd-ac8374c92ed6,user-agent:kubelet/v1.27.3 (linux/amd64) kubernetes/25b4e43,verb:GET (26-Jul-2023 10:00:32.187) (total time: 528ms):
Trace[1098989215]: ---"About to write a response" 528ms (10:00:32.716)
Trace[1098989215]: [528.665507ms] [528.665507ms] END

* 
* ==> kube-apiserver [998d2c1540b6] <==
* I0726 09:58:37.053175       1 server.go:553] external host was not specified, using 192.168.49.2
I0726 09:58:37.236472       1 server.go:166] Version: v1.27.3
I0726 09:58:37.236578       1 server.go:168] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0726 09:58:42.530990       1 shared_informer.go:311] Waiting for caches to sync for node_authorizer
I0726 09:58:43.004914       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0726 09:58:43.004933       1 plugins.go:161] Loaded 13 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,ClusterTrustBundleAttest,CertificateSubjectRestriction,ValidatingAdmissionPolicy,ValidatingAdmissionWebhook,ResourceQuota.
W0726 09:59:01.537901       1 logging.go:59] [core] [Channel #3 SubChannel #4] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: authentication handshake failed: context canceled"
W0726 09:59:01.537902       1 logging.go:59] [core] [Channel #1 SubChannel #2] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: authentication handshake failed: context deadline exceeded"
E0726 09:59:03.597248       1 run.go:74] "command failed" err="context deadline exceeded"

* 
* ==> kube-controller-manager [41869e2ce5ad] <==
* I0726 09:59:45.915996       1 publisher.go:101] Starting root CA certificate configmap publisher
I0726 09:59:45.916081       1 shared_informer.go:311] Waiting for caches to sync for crt configmap
I0726 09:59:45.917575       1 controllermanager.go:638] "Started controller" controller="persistentvolume-binder"
I0726 09:59:45.917824       1 pv_controller_base.go:323] "Starting persistent volume controller"
I0726 09:59:45.917913       1 shared_informer.go:311] Waiting for caches to sync for persistent volume
I0726 09:59:45.919246       1 controllermanager.go:638] "Started controller" controller="pv-protection"
I0726 09:59:45.920017       1 pv_protection_controller.go:78] "Starting PV protection controller"
I0726 09:59:45.920115       1 shared_informer.go:311] Waiting for caches to sync for PV protection
I0726 09:59:45.928766       1 shared_informer.go:311] Waiting for caches to sync for resource quota
I0726 09:59:46.012185       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I0726 09:59:46.012225       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0726 09:59:46.012237       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I0726 09:59:46.012271       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I0726 09:59:46.080135       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I0726 09:59:46.083884       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I0726 09:59:46.106948       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0726 09:59:46.108188       1 shared_informer.go:318] Caches are synced for expand
I0726 09:59:46.108495       1 actual_state_of_world.go:547] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0726 09:59:46.109926       1 shared_informer.go:318] Caches are synced for namespace
I0726 09:59:46.110356       1 shared_informer.go:318] Caches are synced for PV protection
I0726 09:59:46.111851       1 shared_informer.go:318] Caches are synced for service account
I0726 09:59:46.112433       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I0726 09:59:46.113201       1 shared_informer.go:318] Caches are synced for TTL after finished
I0726 09:59:46.113327       1 shared_informer.go:318] Caches are synced for TTL
I0726 09:59:46.116950       1 shared_informer.go:318] Caches are synced for crt configmap
I0726 09:59:46.130374       1 shared_informer.go:318] Caches are synced for GC
I0726 09:59:46.130576       1 shared_informer.go:318] Caches are synced for resource quota
I0726 09:59:46.131752       1 shared_informer.go:318] Caches are synced for resource quota
I0726 09:59:46.154339       1 shared_informer.go:318] Caches are synced for endpoint_slice
I0726 09:59:46.173181       1 shared_informer.go:318] Caches are synced for PVC protection
I0726 09:59:46.173937       1 shared_informer.go:318] Caches are synced for node
I0726 09:59:46.174977       1 range_allocator.go:174] "Sending events to api server"
I0726 09:59:46.175078       1 shared_informer.go:318] Caches are synced for taint
I0726 09:59:46.175240       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I0726 09:59:46.175382       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I0726 09:59:46.175647       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I0726 09:59:46.175795       1 range_allocator.go:178] "Starting range CIDR allocator"
I0726 09:59:46.175867       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0726 09:59:46.175948       1 shared_informer.go:318] Caches are synced for cidrallocator
I0726 09:59:46.176022       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0726 09:59:46.176118       1 taint_manager.go:211] "Sending events to api server"
I0726 09:59:46.176362       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0726 09:59:46.177745       1 shared_informer.go:318] Caches are synced for stateful set
I0726 09:59:46.178754       1 shared_informer.go:318] Caches are synced for cronjob
I0726 09:59:46.187060       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0726 09:59:46.211799       1 shared_informer.go:318] Caches are synced for daemon sets
I0726 09:59:46.211941       1 shared_informer.go:318] Caches are synced for attach detach
I0726 09:59:46.212322       1 shared_informer.go:318] Caches are synced for deployment
I0726 09:59:46.234571       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I0726 09:59:46.234873       1 shared_informer.go:318] Caches are synced for HPA
I0726 09:59:46.234960       1 shared_informer.go:318] Caches are synced for endpoint
I0726 09:59:46.245695       1 shared_informer.go:318] Caches are synced for persistent volume
I0726 09:59:46.246172       1 shared_informer.go:318] Caches are synced for ReplicationController
I0726 09:59:46.246538       1 shared_informer.go:318] Caches are synced for job
I0726 09:59:46.246677       1 shared_informer.go:318] Caches are synced for ephemeral
E0726 09:59:46.247979       1 attach_detach_controller.go:455] "Error creating spec for volume of pod" err="error processing PVC \"default\"/\"wordpress-logs-pvc\": failed to find PVC default/wordpress-logs-pvc in PVCInformer cache: persistentvolumeclaim \"wordpress-logs-pvc\" not found" pod="default/wordpress-5b9c7dd89f-f7cjr" volumeName="wordpress-logs"
I0726 09:59:46.251064       1 shared_informer.go:318] Caches are synced for disruption
I0726 09:59:46.604386       1 shared_informer.go:318] Caches are synced for garbage collector
I0726 09:59:46.604570       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I0726 09:59:46.613249       1 shared_informer.go:318] Caches are synced for garbage collector

* 
* ==> kube-controller-manager [60efc284d44c] <==
* I0726 09:58:37.384514       1 serving.go:348] Generated self-signed cert in-memory
I0726 09:58:41.567474       1 controllermanager.go:187] "Starting" version="v1.27.3"
I0726 09:58:41.567506       1 controllermanager.go:189] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0726 09:58:41.962649       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0726 09:58:41.962753       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0726 09:58:41.963439       1 secure_serving.go:210] Serving securely on 127.0.0.1:10257
I0726 09:58:42.141050       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
E0726 09:59:04.684441       1 controllermanager.go:233] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: Get \"https://192.168.49.2:8443/healthz\": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54728->192.168.49.2:8443: read: connection reset by peer"

* 
* ==> kube-proxy [34e3bacf124d] <==
* E0725 18:28:46.691867       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:28:48.158625       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:00.332972       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": net/http: TLS handshake timeout
E0725 18:29:15.273365       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36434->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:23.857318       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
I0725 18:29:43.044201       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0725 18:29:43.044412       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I0725 18:29:43.044493       1 server_others.go:554] "Using iptables proxy"
I0725 18:29:46.146795       1 server_others.go:192] "Using iptables Proxier"
I0725 18:29:46.146898       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0725 18:29:46.146916       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0725 18:29:46.146950       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0725 18:29:46.213374       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0725 18:29:46.296352       1 server.go:658] "Version info" version="v1.27.3"
I0725 18:29:46.296380       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0725 18:29:46.580022       1 config.go:315] "Starting node config controller"
I0725 18:29:46.580096       1 shared_informer.go:311] Waiting for caches to sync for node config
I0725 18:29:46.585041       1 config.go:188] "Starting service config controller"
I0725 18:29:46.585059       1 shared_informer.go:311] Waiting for caches to sync for service config
I0725 18:29:46.585097       1 config.go:97] "Starting endpoint slice config controller"
I0725 18:29:46.585101       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0725 18:29:46.780867       1 shared_informer.go:318] Caches are synced for node config
I0725 18:29:46.786080       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0725 18:29:46.985539       1 shared_informer.go:318] Caches are synced for service config
I0725 18:31:50.543872       1 trace.go:219] Trace[240614871]: "iptables ChainExists" (25-Jul-2023 18:31:46.219) (total time: 2939ms):
Trace[240614871]: [2.939319485s] [2.939319485s] END
I0725 18:31:50.543907       1 trace.go:219] Trace[1105824195]: "iptables ChainExists" (25-Jul-2023 18:31:46.218) (total time: 2173ms):
Trace[1105824195]: [2.173482681s] [2.173482681s] END
I0725 18:32:22.616684       1 trace.go:219] Trace[213684704]: "iptables ChainExists" (25-Jul-2023 18:32:16.508) (total time: 6107ms):
Trace[213684704]: [6.107707444s] [6.107707444s] END
I0725 18:32:22.616777       1 trace.go:219] Trace[487336192]: "iptables ChainExists" (25-Jul-2023 18:32:16.508) (total time: 6107ms):
Trace[487336192]: [6.107886653s] [6.107886653s] END
I0725 18:34:21.377797       1 trace.go:219] Trace[1756903456]: "iptables ChainExists" (25-Jul-2023 18:34:16.218) (total time: 4524ms):
Trace[1756903456]: [4.524450678s] [4.524450678s] END
I0725 18:34:21.377905       1 trace.go:219] Trace[1188129977]: "iptables ChainExists" (25-Jul-2023 18:34:16.219) (total time: 4422ms):
Trace[1188129977]: [4.422934312s] [4.422934312s] END

* 
* ==> kube-proxy [64a3db268087] <==
* E0726 09:58:23.107283       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:58:24.495061       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:58:26.871885       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:58:31.472020       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:58:49.713458       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": net/http: TLS handshake timeout
E0726 09:59:05.815158       1 node.go:130] Failed to retrieve node info: Get "https://control-plane.minikube.internal:8443/api/v1/nodes/minikube": dial tcp 192.168.49.2:8443: connect: connection refused
I0726 09:59:05.815191       1 server.go:823] "Can't determine this node's IP, assuming 127.0.0.1; if this is incorrect, please set the --bind-address flag"
I0726 09:59:05.815211       1 server_others.go:110] "Detected node IP" address="127.0.0.1"
I0726 09:59:05.815230       1 server_others.go:554] "Using iptables proxy"
I0726 09:59:10.063303       1 server_others.go:192] "Using iptables Proxier"
I0726 09:59:10.063337       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0726 09:59:10.063344       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0726 09:59:10.063379       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0726 09:59:10.326240       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0726 09:59:10.327009       1 server.go:658] "Version info" version="v1.27.3"
I0726 09:59:10.327020       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0726 09:59:10.380061       1 config.go:188] "Starting service config controller"
I0726 09:59:10.380223       1 shared_informer.go:311] Waiting for caches to sync for service config
I0726 09:59:10.533889       1 config.go:97] "Starting endpoint slice config controller"
I0726 09:59:10.533962       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0726 09:59:10.534374       1 config.go:315] "Starting node config controller"
I0726 09:59:10.534466       1 shared_informer.go:311] Waiting for caches to sync for node config
W0726 09:59:10.645644       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.645853       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:10.647698       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.647816       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:10.648155       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.648247       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.956708       1 event_broadcaster.go:274] Unable to write event: 'Post "https://control-plane.minikube.internal:8443/apis/events.k8s.io/v1/namespaces/default/events": dial tcp 192.168.49.2:8443: connect: connection refused' (may retry after sleeping)
W0726 09:59:11.759666       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:11.759701       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:11.846690       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:11.846725       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:12.170033       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:12.170128       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:13.646242       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:13.646348       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:14.532194       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:14.532228       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:14.672334       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:14.672371       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:17.718689       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:17.718731       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:18.302263       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:18.302346       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:19.077079       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:19.077116       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
I0726 09:59:32.697245       1 shared_informer.go:318] Caches are synced for service config
I0726 09:59:32.734566       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0726 09:59:32.749000       1 shared_informer.go:318] Caches are synced for node config

* 
* ==> kube-scheduler [08b9e941b48d] <==
* Trace[1062269437]: ---"Objects listed" error:Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (09:58:49.442)
Trace[1062269437]: [10.000637187s] [10.000637187s] END
E0726 09:58:49.442479       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:58:49.620653       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0726 09:58:49.620694       1 trace.go:219] Trace[1372887654]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (26-Jul-2023 09:58:39.619) (total time: 10001ms):
Trace[1372887654]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (09:58:49.620)
Trace[1372887654]: [10.001508004s] [10.001508004s] END
E0726 09:58:49.620704       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:58:59.198931       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0726 09:58:59.199127       1 trace.go:219] Trace[2125717655]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (26-Jul-2023 09:58:49.197) (total time: 10001ms):
Trace[2125717655]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (09:58:59.198)
Trace[2125717655]: [10.00116149s] [10.00116149s] END
E0726 09:58:59.199201       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:59:00.737089       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0726 09:59:00.737169       1 trace.go:219] Trace[1786108080]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (26-Jul-2023 09:58:50.736) (total time: 10000ms):
Trace[1786108080]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (09:59:00.737)
Trace[1786108080]: [10.000889104s] [10.000889104s] END
E0726 09:59:00.737183       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:59:01.263709       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0726 09:59:01.263929       1 trace.go:219] Trace[1641843211]: "Reflector ListAndWatch" name:pkg/server/dynamiccertificates/configmap_cafile_content.go:206 (26-Jul-2023 09:58:51.263) (total time: 10000ms):
Trace[1641843211]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (09:59:01.263)
Trace[1641843211]: [10.000843249s] [10.000843249s] END
E0726 09:59:01.264043       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:59:01.295862       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0726 09:59:01.295909       1 trace.go:219] Trace[1304154382]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (26-Jul-2023 09:58:51.294) (total time: 10001ms):
Trace[1304154382]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (09:59:01.295)
Trace[1304154382]: [10.001352622s] [10.001352622s] END
E0726 09:59:01.295922       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0726 09:59:04.606901       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54694->192.168.49.2:8443: read: connection reset by peer
E0726 09:59:04.607115       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54694->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:04.607287       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54688->192.168.49.2:8443: read: connection reset by peer
E0726 09:59:04.607363       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54688->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:04.607502       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54680->192.168.49.2:8443: read: connection reset by peer
E0726 09:59:04.607627       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54680->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:04.607765       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54714->192.168.49.2:8443: read: connection reset by peer
E0726 09:59:04.607859       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54714->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:04.608083       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54664->192.168.49.2:8443: read: connection reset by peer
I0726 09:59:04.608219       1 trace.go:219] Trace[533328184]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (26-Jul-2023 09:58:54.594) (total time: 10013ms):
Trace[533328184]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54664->192.168.49.2:8443: read: connection reset by peer 10013ms (09:59:04.608)
Trace[533328184]: [10.013580373s] [10.013580373s] END
E0726 09:59:04.608286       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54664->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:04.609736       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54696->192.168.49.2:8443: read: connection reset by peer
E0726 09:59:04.609763       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:54696->192.168.49.2:8443: read: connection reset by peer
W0726 09:59:05.109981       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:05.110012       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:08.275239       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:08.275462       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:08.311860       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:08.312070       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:10.218523       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.218648       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:10.430704       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0726 09:59:10.430737       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0726 09:59:31.760316       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0726 09:59:31.760465       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0726 09:59:31.760315       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0726 09:59:31.760623       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0726 09:59:32.603796       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0726 09:59:32.603837       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
I0726 09:59:45.214256       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kube-scheduler [4aaae4c4f520] <==
* Trace[358395105]: ---"Objects listed" error:Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (18:29:04.111)
Trace[358395105]: [10.000802403s] [10.000802403s] END
E0725 18:29:04.111149       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0725 18:29:04.235398       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0725 18:29:04.235455       1 trace.go:219] Trace[500330609]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (25-Jul-2023 18:28:54.234) (total time: 10001ms):
Trace[500330609]: ---"Objects listed" error:Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (18:29:04.235)
Trace[500330609]: [10.00137558s] [10.00137558s] END
E0725 18:29:04.235466       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0725 18:29:15.203029       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:15.203060       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0725 18:29:15.272013       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36484->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272045       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36484->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272121       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36486->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272143       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36486->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272188       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36502->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272197       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36506->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272203       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36502->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272210       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36506->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272217       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36512->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272226       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36512->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272252       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36482->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272270       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36482->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.272310       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36500->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.272321       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36500->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.273825       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36472->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.273847       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36472->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.273894       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36460->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.273915       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36460->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.273902       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36492->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.273934       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36492->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.273962       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36474->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.273975       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36474->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.273994       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36490->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.274006       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36490->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.274026       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36498->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.274039       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36498->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:15.274061       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36462->192.168.49.2:8443: read: connection reset by peer
E0725 18:29:15.274075       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused - error from a previous attempt: read tcp 192.168.49.2:36462->192.168.49.2:8443: read: connection reset by peer
W0725 18:29:28.863093       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:28.863220       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0725 18:29:30.698781       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:30.699002       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0725 18:29:31.051802       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:31.051834       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0725 18:29:32.008754       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0725 18:29:32.008854       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0725 18:29:35.087615       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0725 18:29:35.087903       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0725 18:29:35.087742       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0725 18:29:35.088061       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0725 18:29:35.088002       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0725 18:29:35.088205       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0725 18:29:35.088049       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0725 18:29:35.088333       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
I0725 18:30:18.249178       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0726 09:57:03.369854       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0726 09:57:03.459595       1 secure_serving.go:255] Stopped listening on 127.0.0.1:10259
I0726 09:57:03.459650       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
E0726 09:57:03.760769       1 scheduling_queue.go:1135] "Error while retrieving next pod from scheduling queue" err="scheduling queue is closed"
E0726 09:57:03.898715       1 run.go:74] "command failed" err="finished without leader elect"

* 
* ==> kubelet <==
* Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.123662    1232 status_manager.go:809] "Failed to get status for pod" podUID=4a1d88b0-addc-448b-8e11-3b76d7d41bc0 pod="logging/fluentd-ff92m" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/logging/pods/fluentd-ff92m\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.123740    1232 status_manager.go:809] "Failed to get status for pod" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa pod="default/wordpress-mysql-c7b7fcc69-k6h2p" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/wordpress-mysql-c7b7fcc69-k6h2p\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.123823    1232 status_manager.go:809] "Failed to get status for pod" podUID=e14e2f92c469337ac62a252dad99dcc5 pod="kube-system/kube-scheduler-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-scheduler-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.123950    1232 status_manager.go:809] "Failed to get status for pod" podUID=be6fba94-60a1-4142-b1eb-31163b3beb7a pod="kube-system/coredns-5d78c9869d-2sjp8" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/coredns-5d78c9869d-2sjp8\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124075    1232 status_manager.go:809] "Failed to get status for pod" podUID=4e275e35949ad3fdfeb753c1099308e7 pod="kube-system/kube-apiserver-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-apiserver-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124171    1232 status_manager.go:809] "Failed to get status for pod" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3 pod="default/wordpress-b979fc4c6-zfcwm" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/pods/wordpress-b979fc4c6-zfcwm\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124428    1232 status_manager.go:809] "Failed to get status for pod" podUID=2c8e03f5-000d-48ea-9287-f5e74f36db11 pod="kube-system/kube-proxy-xs8fq" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-proxy-xs8fq\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124578    1232 status_manager.go:809] "Failed to get status for pod" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712 pod="kube-system/fluentd-vmxds" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/fluentd-vmxds\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124731    1232 status_manager.go:809] "Failed to get status for pod" podUID=e33f7a2a0d6aad5df18c7258d3116e25 pod="kube-system/kube-controller-manager-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/kube-controller-manager-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:19 minikube kubelet[1232]: I0726 09:59:19.124854    1232 status_manager.go:809] "Failed to get status for pod" podUID=8af0e85a28544808d52bb7c47ad824ed pod="kube-system/etcd-minikube" err="Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods/etcd-minikube\": dial tcp 192.168.49.2:8443: connect: connection refused"
Jul 26 09:59:20 minikube kubelet[1232]: E0726 09:59:20.512258    1232 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-controller-manager-minikube.17752dceb52e859b", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"", ResourceVersion:"79825", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kube-system", Name:"kube-controller-manager-minikube", UID:"e33f7a2a0d6aad5df18c7258d3116e25", APIVersion:"v1", ResourceVersion:"", FieldPath:"spec.containers{kube-controller-manager}"}, Reason:"Unhealthy", Message:"Liveness probe failed: Get \"https://127.0.0.1:10257/healthz\": dial tcp 127.0.0.1:10257: connect: connection refused", Source:v1.EventSource{Component:"kubelet", Host:"minikube"}, FirstTimestamp:time.Date(2023, time.July, 25, 17, 53, 20, 0, time.Local), LastTimestamp:time.Date(2023, time.July, 26, 9, 57, 0, 973348325, time.Local), Count:8, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'Patch "https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/events/kube-controller-manager-minikube.17752dceb52e859b": dial tcp 192.168.49.2:8443: connect: connection refused'(may retry after sleeping)
Jul 26 09:59:21 minikube kubelet[1232]: I0726 09:59:21.123651    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 09:59:21 minikube kubelet[1232]: E0726 09:59:21.123867    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=wordpress pod=wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3)\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3
Jul 26 09:59:21 minikube kubelet[1232]: I0726 09:59:21.124296    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 09:59:21 minikube kubelet[1232]: E0726 09:59:21.124414    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=mysql pod=wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa)\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 09:59:21 minikube kubelet[1232]: E0726 09:59:21.154715    1232 desired_state_of_world_populator.go:295] "Error processing volume" err="error processing PVC default/wp-pv-claim: failed to fetch PVC from API server: Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/persistentvolumeclaims/wp-pv-claim\": dial tcp 192.168.49.2:8443: connect: connection refused" pod="default/wordpress-b979fc4c6-zfcwm" volumeName="wordpress-persistent-storage"
Jul 26 09:59:21 minikube kubelet[1232]: E0726 09:59:21.155050    1232 desired_state_of_world_populator.go:295] "Error processing volume" err="error processing PVC default/mysql-pv-claim: failed to fetch PVC from API server: Get \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/persistentvolumeclaims/mysql-pv-claim\": dial tcp 192.168.49.2:8443: connect: connection refused" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" volumeName="mysql-persistent-storage"
Jul 26 09:59:25 minikube kubelet[1232]: I0726 09:59:25.124865    1232 scope.go:115] "RemoveContainer" containerID="70bda415789a66d32e63f337139d3949e15a38298248c0bcddbd242d291e3e86"
Jul 26 09:59:27 minikube kubelet[1232]: I0726 09:59:27.123877    1232 scope.go:115] "RemoveContainer" containerID="60efc284d44cc13f3c21bb16aabc021740de30313d26d795c79458db4049a663"
Jul 26 09:59:32 minikube kubelet[1232]: I0726 09:59:32.189094    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.189322    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=mysql pod=wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa)\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 09:59:32 minikube kubelet[1232]: I0726 09:59:32.220469    1232 scope.go:115] "RemoveContainer" containerID="b14c819ebe40fbe8422acfdc6a68fc321ce41bbd366815cf242b10675f92aa8e"
Jul 26 09:59:32 minikube kubelet[1232]: I0726 09:59:32.220741    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.220881    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.597194    1232 reflector.go:148] object-"kube-system"/"kube-root-ca.crt": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jul 26 09:59:32 minikube kubelet[1232]: W0726 09:59:32.597271    1232 reflector.go:533] object-"default"/"mysql-pass-fm6bc796b7": failed to list *v1.Secret: secrets "mysql-pass-fm6bc796b7" is forbidden: User "system:node:minikube" cannot list resource "secrets" in API group "" in the namespace "default": no relationship found between node 'minikube' and this object
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.597285    1232 reflector.go:148] object-"default"/"mysql-pass-fm6bc796b7": Failed to watch *v1.Secret: failed to list *v1.Secret: secrets "mysql-pass-fm6bc796b7" is forbidden: User "system:node:minikube" cannot list resource "secrets" in API group "" in the namespace "default": no relationship found between node 'minikube' and this object
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.597475    1232 reflector.go:148] object-"logging"/"fluentd-config": Failed to watch *v1.ConfigMap: unknown (get configmaps)
Jul 26 09:59:32 minikube kubelet[1232]: E0726 09:59:32.597602    1232 desired_state_of_world_populator.go:295] "Error processing volume" err="error processing PVC default/mysql-pv-claim: failed to fetch PVC from API server: persistentvolumeclaims \"mysql-pv-claim\" is forbidden: User \"system:node:minikube\" cannot get resource \"persistentvolumeclaims\" in API group \"\" in the namespace \"default\": no relationship found between node 'minikube' and this object" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" volumeName="mysql-persistent-storage"
Jul 26 09:59:33 minikube kubelet[1232]: I0726 09:59:33.125048    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 09:59:33 minikube kubelet[1232]: E0726 09:59:33.125235    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=wordpress pod=wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3)\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3
Jul 26 09:59:34 minikube kubelet[1232]: I0726 09:59:34.290401    1232 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="b14c819ebe40fbe8422acfdc6a68fc321ce41bbd366815cf242b10675f92aa8e"
Jul 26 09:59:34 minikube kubelet[1232]: I0726 09:59:34.290666    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 09:59:34 minikube kubelet[1232]: E0726 09:59:34.291366    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 09:59:46 minikube kubelet[1232]: I0726 09:59:46.123894    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 09:59:46 minikube kubelet[1232]: E0726 09:59:46.124548    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=mysql pod=wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa)\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 09:59:47 minikube kubelet[1232]: I0726 09:59:47.123880    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 09:59:47 minikube kubelet[1232]: E0726 09:59:47.124240    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=wordpress pod=wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3)\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3
Jul 26 09:59:47 minikube kubelet[1232]: I0726 09:59:47.124316    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 09:59:47 minikube kubelet[1232]: E0726 09:59:47.124779    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 09:59:57 minikube kubelet[1232]: I0726 09:59:57.124905    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 09:59:58 minikube kubelet[1232]: E0726 09:59:58.127000    1232 kuberuntime_manager.go:1212] container &Container{Name:mysql,Image:mysql:8.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:mysql,HostPort:0,ContainerPort:3306,Protocol:TCP,HostIP:,},},Env:[]EnvVar{EnvVar{Name:MYSQL_ROOT_PASSWORD,Value:,ValueFrom:&EnvVarSource{FieldRef:nil,ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:&SecretKeySelector{LocalObjectReference:LocalObjectReference{Name:mysql-pass-fm6bc796b7,},Key:password,Optional:nil,},},},EnvVar{Name:MYSQL_DATABASE,Value:wordpress,ValueFrom:nil,},EnvVar{Name:MYSQL_USER,Value:wordpress,ValueFrom:nil,},EnvVar{Name:MYSQL_PASSWORD,Value:,ValueFrom:&EnvVarSource{FieldRef:nil,ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:&SecretKeySelector{LocalObjectReference:LocalObjectReference{Name:mysql-pass-fm6bc796b7,},Key:password,Optional:nil,},},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:mysql-persistent-storage,ReadOnly:false,MountPath:/var/lib/mysql,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:fluentd-logging,ReadOnly:false,MountPath:/var/log/mysql,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-8t6qr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa): CreateContainerConfigError: failed to sync secret cache: timed out waiting for the condition
Jul 26 09:59:58 minikube kubelet[1232]: E0726 09:59:58.127059    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CreateContainerConfigError: \"failed to sync secret cache: timed out waiting for the condition\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 09:59:59 minikube kubelet[1232]: I0726 09:59:59.124575    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 09:59:59 minikube kubelet[1232]: E0726 09:59:59.125273    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 10:00:01 minikube kubelet[1232]: I0726 10:00:01.125013    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 10:00:02 minikube kubelet[1232]: E0726 10:00:02.127665    1232 kuberuntime_manager.go:1212] container &Container{Name:wordpress,Image:wordpress:6.2.1-apache,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:wordpress,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{EnvVar{Name:WORDPRESS_DB_HOST,Value:wordpress-mysql,ValueFrom:nil,},EnvVar{Name:WORDPRESS_DB_PASSWORD,Value:,ValueFrom:&EnvVarSource{FieldRef:nil,ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:&SecretKeySelector{LocalObjectReference:LocalObjectReference{Name:mysql-pass-fm6bc796b7,},Key:password,Optional:nil,},},},EnvVar{Name:WORDPRESS_DB_USER,Value:wordpress,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:wordpress-persistent-storage,ReadOnly:false,MountPath:/var/www/html,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:fluentd-logging,ReadOnly:true,MountPath:/var/log/wordpress,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-d4lrv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},} start failed in pod wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3): CreateContainerConfigError: failed to sync secret cache: timed out waiting for the condition
Jul 26 10:00:02 minikube kubelet[1232]: E0726 10:00:02.128299    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CreateContainerConfigError: \"failed to sync secret cache: timed out waiting for the condition\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3
Jul 26 10:00:12 minikube kubelet[1232]: I0726 10:00:12.123269    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 10:00:12 minikube kubelet[1232]: E0726 10:00:12.123468    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=mysql pod=wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa)\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 10:00:13 minikube kubelet[1232]: I0726 10:00:13.123173    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 10:00:13 minikube kubelet[1232]: E0726 10:00:13.123341    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 10:00:17 minikube kubelet[1232]: I0726 10:00:17.123310    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 10:00:17 minikube kubelet[1232]: E0726 10:00:17.123496    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=wordpress pod=wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3)\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3
Jul 26 10:00:27 minikube kubelet[1232]: I0726 10:00:27.124615    1232 scope.go:115] "RemoveContainer" containerID="9b18ebf6febf786fb5fea5d36e3809f2f4cbfd956e9edaf7caca8e8b683ac2c5"
Jul 26 10:00:27 minikube kubelet[1232]: E0726 10:00:27.124761    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"fluentd\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=fluentd pod=fluentd-vmxds_kube-system(37cd9a52-db17-49e9-85ec-f9fb6e0c7712)\"" pod="kube-system/fluentd-vmxds" podUID=37cd9a52-db17-49e9-85ec-f9fb6e0c7712
Jul 26 10:00:27 minikube kubelet[1232]: I0726 10:00:27.125045    1232 scope.go:115] "RemoveContainer" containerID="d0b1b0ee8219de7cbae9e78d372f16e631e294bee3b5cf2e6a55767efb13a3cb"
Jul 26 10:00:27 minikube kubelet[1232]: E0726 10:00:27.125173    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=mysql pod=wordpress-mysql-c7b7fcc69-k6h2p_default(16e067ea-6b7e-4895-96fb-d2dd84d9dfaa)\"" pod="default/wordpress-mysql-c7b7fcc69-k6h2p" podUID=16e067ea-6b7e-4895-96fb-d2dd84d9dfaa
Jul 26 10:00:32 minikube kubelet[1232]: I0726 10:00:32.123245    1232 scope.go:115] "RemoveContainer" containerID="178a7de664be0e46c1d90623973ed8f2a138f56b8316127a36013d7903acda5d"
Jul 26 10:00:32 minikube kubelet[1232]: E0726 10:00:32.124033    1232 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"wordpress\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=wordpress pod=wordpress-b979fc4c6-zfcwm_default(589b9bb8-e1a7-4c30-b065-a3f8ebe089e3)\"" pod="default/wordpress-b979fc4c6-zfcwm" podUID=589b9bb8-e1a7-4c30-b065-a3f8ebe089e3

* 
* ==> storage-provisioner [2f9bb18d7c1d] <==
* I0726 09:59:29.163728       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0726 09:59:32.991634       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0726 09:59:32.991911       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0726 09:59:52.272702       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0726 09:59:52.273273       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"56fa6f4e-b777-466e-8061-92a420e63a21", APIVersion:"v1", ResourceVersion:"125700", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_bdbab705-3bc3-40c4-b6c0-07a582c18f5e became leader
I0726 09:59:52.273438       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_bdbab705-3bc3-40c4-b6c0-07a582c18f5e!
I0726 09:59:52.528547       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_bdbab705-3bc3-40c4-b6c0-07a582c18f5e!

* 
* ==> storage-provisioner [70bda415789a] <==
* I0726 09:58:46.020747       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0726 09:58:56.027061       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": net/http: TLS handshake timeout

